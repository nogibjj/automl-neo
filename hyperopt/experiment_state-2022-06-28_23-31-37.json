{
  "checkpoints": [
    "{\n  \"stub\": false,\n  \"trainable_name\": \"trainable_func_f2we_ZX\",\n  \"trial_id\": \"fb9ab05e\",\n  \"config\": {\n    \"trainer.learning_rate\": 0.025,\n    \"trainer.batch_size\": 2048,\n    \"trainer.decay_rate\": 0.95,\n    \"trainer.decay_steps\": 500,\n    \"combiner.size\": 32,\n    \"combiner.output_size\": 8,\n    \"combiner.num_steps\": 4,\n    \"combiner.relaxation_factor\": 1.0,\n    \"combiner.sparsity\": 0.0001,\n    \"combiner.bn_virtual_bs\": 2048,\n    \"combiner.bn_momentum\": 0.3\n  },\n  \"local_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt\",\n  \"evaluated_params\": {\n    \"combiner.bn_momentum\": 0.3,\n    \"combiner.bn_virtual_bs\": 2048,\n    \"combiner.num_steps\": 4,\n    \"combiner.output_size\": 8,\n    \"combiner.relaxation_factor\": 1.0,\n    \"combiner.size\": 32,\n    \"combiner.sparsity\": 0.0001,\n    \"trainer.batch_size\": 2048,\n    \"trainer.decay_rate\": 0.95,\n    \"trainer.decay_steps\": 500,\n    \"trainer.learning_rate\": 0.025\n  },\n  \"experiment_tag\": \"1_combiner_bn_momentum=0.3000,combiner_bn_virtual_bs=2048,combiner_num_steps=4,combiner_output_size=8,combiner_relaxation_factor=1.0000,combiner_size=32,combiner_sparsity=0.0001,trainer_batch_size=2048,trainer_decay_rate=0.9500,trainer_decay_steps=500,trainer_learning_rate=0.0250\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595a6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 1,\n  \"_last_result\": {\n    \"parameters\": \"{\\\"trainer.learning_rate\\\": 0.025, \\\"trainer.batch_size\\\": 2048, \\\"trainer.decay_rate\\\": 0.95, \\\"trainer.decay_steps\\\": 500, \\\"combiner.size\\\": 32, \\\"combiner.output_size\\\": 8, \\\"combiner.num_steps\\\": 4, \\\"combiner.relaxation_factor\\\": 1.0, \\\"combiner.sparsity\\\": 0.0001, \\\"combiner.bn_virtual_bs\\\": 2048, \\\"combiner.bn_momentum\\\": 0.3}\",\n    \"metric_score\": 0.9901849627494812,\n    \"training_stats\": \"{\\\"training\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.26627808809280396, 0.17989811301231384, 0.12115166336297989, 0.07643859088420868, 0.07997114956378937, 0.04956824332475662, 0.05197658762335777], \\\"roc_auc\\\": [0.8082901835441589, 0.9299538731575012, 0.9707050919532776, 0.9881786704063416, 0.9868959188461304, 0.993431568145752, 0.9931352734565735], \\\"accuracy\\\": [0.9040465354919434, 0.9111023545265198, 0.9421230554580688, 0.9679421782493591, 0.9666378498077393, 0.9775280952453613, 0.9769466519355774]}, \\\"combined\\\": {\\\"loss\\\": [0.26635212112159934, 0.1799658554009511, 0.12121414756256854, 0.0764979083869548, 0.08002903026499553, 0.04962514657381689, 0.05203249410260469]}}, \\\"validation\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.25994959473609924, 0.18330249190330505, 0.12807932496070862, 0.08347399532794952, 0.0864425078034401, 0.06180418282747269, 0.06365220248699188], \\\"roc_auc\\\": [0.8111209869384766, 0.9231897592544556, 0.9638838768005371, 0.9855267405509949, 0.9835507869720459, 0.9901849627494812, 0.9893789887428284], \\\"accuracy\\\": [0.9016321301460266, 0.9075871109962463, 0.9359285235404968, 0.96471107006073, 0.9627260565757751, 0.9744155406951904, 0.9737538695335388]}, \\\"combined\\\": {\\\"loss\\\": [0.2600237323276815, 0.18336968552466715, 0.12814138604153413, 0.08353304961929098, 0.08650029308046214, 0.06186100481500034, 0.06370801401862991]}}, \\\"test\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.27491962909698486, 0.18570367991924286, 0.13252046704292297, 0.08754168450832367, 0.08844424039125443, 0.060188814997673035, 0.060222506523132324], \\\"roc_auc\\\": [0.8127028942108154, 0.9286696314811707, 0.9663209319114685, 0.9850084185600281, 0.9834038019180298, 0.989872395992279, 0.990866482257843], \\\"accuracy\\\": [0.8983621001243591, 0.9044835567474365, 0.9355870485305786, 0.9636574387550354, 0.9637125730514526, 0.9744664430618286, 0.9734737873077393]}, \\\"combined\\\": {\\\"loss\\\": [0.2749938599736197, 0.18577003858808894, 0.13258185517042875, 0.08760031849669758, 0.08850186522249714, 0.06024547752531362, 0.06027815251945867]}}}\",\n    \"eval_stats\": \"{}\",\n    \"trial_id\": \"fb9ab05e\",\n    \"trial_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_fb9ab05e/\",\n    \"time_this_iter_s\": 9.772241115570068,\n    \"should_checkpoint\": true,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 7,\n    \"experiment_id\": \"36da87c1449044f59e94313f982f8c52\",\n    \"date\": \"2022-06-28_23-33-34\",\n    \"timestamp\": 1656473614,\n    \"time_total_s\": 112.54873704910278,\n    \"pid\": 44840,\n    \"hostname\": \"C02FR8FUMD6R.grubhub.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"trainer.learning_rate\": 0.025,\n      \"trainer.batch_size\": 2048,\n      \"trainer.decay_rate\": 0.95,\n      \"trainer.decay_steps\": 500,\n      \"combiner.size\": 32,\n      \"combiner.output_size\": 8,\n      \"combiner.num_steps\": 4,\n      \"combiner.relaxation_factor\": 1.0,\n      \"combiner.sparsity\": 0.0001,\n      \"combiner.bn_virtual_bs\": 2048,\n      \"combiner.bn_momentum\": 0.3\n    },\n    \"time_since_restore\": 112.54873704910278,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 7,\n    \"warmup_time\": 0.002440929412841797,\n    \"experiment_tag\": \"1_combiner_bn_momentum=0.3000,combiner_bn_virtual_bs=2048,combiner_num_steps=4,combiner_output_size=8,combiner_relaxation_factor=1.0000,combiner_size=32,combiner_sparsity=0.0001,trainer_batch_size=2048,trainer_decay_rate=0.9500,trainer_decay_steps=500,trainer_learning_rate=0.0250\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1656473614.022177,\n  \"metric_analysis\": {\n    \"metric_score\": {\n      \"max\": 0.9901849627494812,\n      \"min\": 0.8111209869384766,\n      \"avg\": 0.949945432799203,\n      \"last\": 0.9901849627494812,\n      \"last-5-avg\": 0.9830614566802979,\n      \"last-10-avg\": 0.9499454327992031\n    },\n    \"time_this_iter_s\": {\n      \"max\": 22.629406929016113,\n      \"min\": 9.772241115570068,\n      \"avg\": 16.078391007014684,\n      \"last\": 9.772241115570068,\n      \"last-5-avg\": 15.31016960144043,\n      \"last-10-avg\": 16.078391007014684\n    },\n    \"should_checkpoint\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": 1.0,\n      \"last\": true,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 7,\n      \"min\": 1,\n      \"avg\": 4.0,\n      \"last\": 7,\n      \"last-5-avg\": 5.0,\n      \"last-10-avg\": 4.0\n    },\n    \"time_total_s\": {\n      \"max\": 112.54873704910278,\n      \"min\": 13.368482112884521,\n      \"avg\": 69.94429046767098,\n      \"last\": 112.54873704910278,\n      \"last-5-avg\": 88.04873242378235,\n      \"last-10-avg\": 69.94429046767098\n    },\n    \"time_since_restore\": {\n      \"max\": 112.54873704910278,\n      \"min\": 13.368482112884521,\n      \"avg\": 69.94429046767098,\n      \"last\": 112.54873704910278,\n      \"last-5-avg\": 88.04873242378235,\n      \"last-10-avg\": 69.94429046767098\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 7,\n      \"min\": 1,\n      \"avg\": 4.0,\n      \"last\": 7,\n      \"last-5-avg\": 5.0,\n      \"last-10-avg\": 4.0\n    },\n    \"warmup_time\": {\n      \"max\": 0.002440929412841797,\n      \"min\": 0.002440929412841797,\n      \"avg\": 0.002440929412841797,\n      \"last\": 0.002440929412841797,\n      \"last-5-avg\": 0.002440929412841797,\n      \"last-10-avg\": 0.002440929412841797\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"metric_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473feed82300000000473fef896f60000000473fef896f60000000473fefaf9860000000473fefaf9860000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059561000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe9f4b400000000473fed8ac540000000473feed82300000000473fef896f60000000473fef896f60000000473fefaf9860000000473fefaf9860000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740350357a400000047403403aa0400000047402bb6c480000000474027c9ddc00000004740238b6330000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059561000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847402abca9b0000000474036a120d00000004740350357a400000047403403aa0400000047402bb6c480000000474027c9ddc00000004740238b6330000000652e\"\n      }\n    },\n    \"should_checkpoint\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288888888888652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059529000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942888888888888888652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059529000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b034b044b054b064b07652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059530000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b07652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404c8166a6000000474053419dd4000000474056b87664000000474059b1b21c00000047405c231e82000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059561000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847402abca9b0000000474041ffbad400000047404c8166a6000000474053419dd4000000474056b87664000000474059b1b21c00000047405c231e82000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404c8166a6000000474053419dd4000000474056b87664000000474059b1b21c00000047405c231e82000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059561000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847402abca9b0000000474041ffbad400000047404c8166a6000000474053419dd4000000474056b87664000000474059b1b21c00000047405c231e82000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059530000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b034b044b054b064b07652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059530000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b07652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f63ff0000000000473f63ff0000000000473f63ff0000000000473f63ff0000000000473f63ff0000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059561000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f63ff0000000000473f63ff0000000000473f63ff0000000000473f63ff0000000000473f63ff0000000000473f63ff0000000000473f63ff0000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1656473497.8509812,\n  \"logdir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_fb9ab05e\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd2024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd3024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": \"trial_fb9ab05e\",\n  \"custom_dirname\": \"trial_fb9ab05e\",\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": 1,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"trainable_func_f2we_ZX\",\n  \"trial_id\": \"fde53c44\",\n  \"config\": {\n    \"trainer.learning_rate\": 0.005,\n    \"trainer.batch_size\": 512,\n    \"trainer.decay_rate\": 0.95,\n    \"trainer.decay_steps\": 20000,\n    \"combiner.size\": 64,\n    \"combiner.output_size\": 64,\n    \"combiner.num_steps\": 5,\n    \"combiner.relaxation_factor\": 1.5,\n    \"combiner.sparsity\": 0.0001,\n    \"combiner.bn_virtual_bs\": 256,\n    \"combiner.bn_momentum\": 0.1\n  },\n  \"local_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt\",\n  \"evaluated_params\": {\n    \"combiner.bn_momentum\": 0.1,\n    \"combiner.bn_virtual_bs\": 256,\n    \"combiner.num_steps\": 5,\n    \"combiner.output_size\": 64,\n    \"combiner.relaxation_factor\": 1.5,\n    \"combiner.size\": 64,\n    \"combiner.sparsity\": 0.0001,\n    \"trainer.batch_size\": 512,\n    \"trainer.decay_rate\": 0.95,\n    \"trainer.decay_steps\": 20000,\n    \"trainer.learning_rate\": 0.005\n  },\n  \"experiment_tag\": \"5_combiner_bn_momentum=0.1000,combiner_bn_virtual_bs=256,combiner_num_steps=5,combiner_output_size=64,combiner_relaxation_factor=1.5000,combiner_size=64,combiner_sparsity=0.0001,trainer_batch_size=512,trainer_decay_rate=0.9500,trainer_decay_steps=20000,trainer_learning_rate=0.0050\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595a6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 1,\n  \"_last_result\": {\n    \"parameters\": \"{\\\"trainer.learning_rate\\\": 0.005, \\\"trainer.batch_size\\\": 512, \\\"trainer.decay_rate\\\": 0.95, \\\"trainer.decay_steps\\\": 20000, \\\"combiner.size\\\": 64, \\\"combiner.output_size\\\": 64, \\\"combiner.num_steps\\\": 5, \\\"combiner.relaxation_factor\\\": 1.5, \\\"combiner.sparsity\\\": 0.0001, \\\"combiner.bn_virtual_bs\\\": 256, \\\"combiner.bn_momentum\\\": 0.1}\",\n    \"metric_score\": 0.8900913000106812,\n    \"training_stats\": \"{\\\"training\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.2533119022846222, 0.2063780128955841], \\\"roc_auc\\\": [0.830421507358551, 0.8929733037948608], \\\"accuracy\\\": [0.9033393859863281, 0.9031036496162415]}, \\\"combined\\\": {\\\"loss\\\": [0.2533555643640284, 0.20641830653403304]}}, \\\"validation\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.26515889167785645, 0.21037200093269348], \\\"roc_auc\\\": [0.8184343576431274, 0.8900913000106812], \\\"accuracy\\\": [0.8992059826850891, 0.9000882506370544]}, \\\"combined\\\": {\\\"loss\\\": [0.26520254850765923, 0.2104120477270044]}}, \\\"test\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.2612825930118561, 0.21498972177505493], \\\"roc_auc\\\": [0.8336548805236816, 0.8897092342376709], \\\"accuracy\\\": [0.8990790247917175, 0.8975900411605835]}, \\\"combined\\\": {\\\"loss\\\": [0.2613262640115863, 0.21502931974464445]}}}\",\n    \"eval_stats\": \"{}\",\n    \"trial_id\": \"fde53c44\",\n    \"trial_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_fde53c44/\",\n    \"time_this_iter_s\": 38.10450887680054,\n    \"should_checkpoint\": true,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 2,\n    \"experiment_id\": \"cc4f93852c8c4d2e861b2067f3f6e77d\",\n    \"date\": \"2022-06-28_23-33-19\",\n    \"timestamp\": 1656473599,\n    \"time_total_s\": 90.2083420753479,\n    \"pid\": 44863,\n    \"hostname\": \"C02FR8FUMD6R.grubhub.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"trainer.learning_rate\": 0.005,\n      \"trainer.batch_size\": 512,\n      \"trainer.decay_rate\": 0.95,\n      \"trainer.decay_steps\": 20000,\n      \"combiner.size\": 64,\n      \"combiner.output_size\": 64,\n      \"combiner.num_steps\": 5,\n      \"combiner.relaxation_factor\": 1.5,\n      \"combiner.sparsity\": 0.0001,\n      \"combiner.bn_virtual_bs\": 256,\n      \"combiner.bn_momentum\": 0.1\n    },\n    \"time_since_restore\": 90.2083420753479,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 2,\n    \"warmup_time\": 0.004141092300415039,\n    \"experiment_tag\": \"5_combiner_bn_momentum=0.1000,combiner_bn_virtual_bs=256,combiner_num_steps=5,combiner_output_size=64,combiner_relaxation_factor=1.5000,combiner_size=64,combiner_sparsity=0.0001,trainer_batch_size=512,trainer_decay_rate=0.9500,trainer_decay_steps=20000,trainer_learning_rate=0.0050\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1656473599.7981539,\n  \"metric_analysis\": {\n    \"metric_score\": {\n      \"max\": 0.8900913000106812,\n      \"min\": 0.8184343576431274,\n      \"avg\": 0.8542628288269043,\n      \"last\": 0.8900913000106812,\n      \"last-5-avg\": 0.8542628288269043,\n      \"last-10-avg\": 0.8542628288269043\n    },\n    \"time_this_iter_s\": {\n      \"max\": 52.10383319854736,\n      \"min\": 38.10450887680054,\n      \"avg\": 45.10417103767395,\n      \"last\": 38.10450887680054,\n      \"last-5-avg\": 45.10417103767395,\n      \"last-10-avg\": 45.10417103767395\n    },\n    \"should_checkpoint\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": 1.0,\n      \"last\": true,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_total_s\": {\n      \"max\": 90.2083420753479,\n      \"min\": 52.10383319854736,\n      \"avg\": 71.15608763694763,\n      \"last\": 90.2083420753479,\n      \"last-5-avg\": 71.15608763694763,\n      \"last-10-avg\": 71.15608763694763\n    },\n    \"time_since_restore\": {\n      \"max\": 90.2083420753479,\n      \"min\": 52.10383319854736,\n      \"avg\": 71.15608763694763,\n      \"last\": 90.2083420753479,\n      \"last-5-avg\": 71.15608763694763,\n      \"last-10-avg\": 71.15608763694763\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.004141092300415039,\n      \"min\": 0.004141092300415039,\n      \"avg\": 0.004141092300415039,\n      \"last\": 0.004141092300415039,\n      \"last-5-avg\": 0.004141092300415039,\n      \"last-10-avg\": 0.004141092300415039\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"metric_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fea309d40000000473fec7ba0c0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fea309d40000000473fec7ba0c0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404a0d4a680000004740430d608c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404a0d4a680000004740430d608c000000652e\"\n      }\n    },\n    \"should_checkpoint\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288888652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288888652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404a0d4a680000004740568d557a000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404a0d4a680000004740568d557a000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404a0d4a680000004740568d557a000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404a0d4a680000004740568d557a000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f70f64000000000473f70f64000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f70f64000000000473f70f64000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1656473501.564522,\n  \"logdir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_fde53c44\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd2024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd3024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": \"trial_fde53c44\",\n  \"custom_dirname\": \"trial_fde53c44\",\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": 1,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595000b0000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d944b018c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0f5f54756e65436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565948c582f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f68797065726f70742f747269616c5f66646535336334342f636865636b706f696e745f3030303030322f948c06726573756c74947d94288c0a706172616d657465727394583b0100007b22747261696e65722e6c6561726e696e675f72617465223a20302e3030352c2022747261696e65722e62617463685f73697a65223a203531322c2022747261696e65722e64656361795f72617465223a20302e39352c2022747261696e65722e64656361795f7374657073223a2032303030302c2022636f6d62696e65722e73697a65223a2036342c2022636f6d62696e65722e6f75747075745f73697a65223a2036342c2022636f6d62696e65722e6e756d5f7374657073223a20352c2022636f6d62696e65722e72656c61786174696f6e5f666163746f72223a20312e352c2022636f6d62696e65722e7370617273697479223a20302e303030312c2022636f6d62696e65722e626e5f7669727475616c5f6273223a203235362c2022636f6d62696e65722e626e5f6d6f6d656e74756d223a20302e317d948c0c6d65747269635f73636f726594473fec7ba0c00000008c0e747261696e696e675f73746174739458f10200007b22747261696e696e67223a207b2268617a6172646f7573223a207b226c6f7373223a205b302e323533333131393032323834363232322c20302e323036333738303132383935353834315d2c2022726f635f617563223a205b302e3833303432313530373335383535312c20302e383932393733333033373934383630385d2c20226163637572616379223a205b302e393033333339333835393836333238312c20302e393033313033363439363136323431355d7d2c2022636f6d62696e6564223a207b226c6f7373223a205b302e323533333535353634333634303238342c20302e32303634313833303635333430333330345d7d7d2c202276616c69646174696f6e223a207b2268617a6172646f7573223a207b226c6f7373223a205b302e32363531353838393136373738353634352c20302e32313033373230303039333236393334385d2c2022726f635f617563223a205b302e383138343334333537363433313237342c20302e383930303931333030303130363831325d2c20226163637572616379223a205b302e383939323035393832363835303839312c20302e393030303838323530363337303534345d7d2c2022636f6d62696e6564223a207b226c6f7373223a205b302e32363532303235343835303736353932332c20302e323130343132303437373237303034345d7d7d2c202274657374223a207b2268617a6172646f7573223a207b226c6f7373223a205b302e323631323832353933303131383536312c20302e32313439383937323137373530353439335d2c2022726f635f617563223a205b302e383333363534383830353233363831362c20302e383839373039323334323337363730395d2c20226163637572616379223a205b302e383939303739303234373931373137352c20302e383937353930303431313630353833355d7d2c2022636f6d62696e6564223a207b226c6f7373223a205b302e323631333236323634303131353836332c20302e32313530323933313937343436343434355d7d7d7d948c0a6576616c5f7374617473948c027b7d948c08747269616c5f6964948c086664653533633434948c09747269616c5f646972948c462f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f68797065726f70742f747269616c5f66646535336334342f948c1074696d655f746869735f697465725f73944740430d608c0000008c1173686f756c645f636865636b706f696e7494888c04646f6e6594888c0f74696d6573746570735f746f74616c944e8c0e657069736f6465735f746f74616c944e68084b028c0d6578706572696d656e745f6964948c206363346639333835326338633464326538363162323036376633663665373764948c0464617465948c13323032322d30362d32385f32332d33332d3139948c0974696d657374616d70944affc7bb628c0c74696d655f746f74616c5f73944740568d557a0000008c03706964944d3faf8c08686f73746e616d65948c1a43303246523846554d4436522e677275626875622e6c6f63616c948c076e6f64655f6970948c093132372e302e302e31948c06636f6e666967947d94288c15747261696e65722e6c6561726e696e675f7261746594473f747ae147ae147b8c12747261696e65722e62617463685f73697a65944d00028c12747261696e65722e64656361795f7261746594473fee6666666666668c13747261696e65722e64656361795f7374657073944d204e8c0d636f6d62696e65722e73697a65944b408c14636f6d62696e65722e6f75747075745f73697a65944b408c12636f6d62696e65722e6e756d5f7374657073944b058c1a636f6d62696e65722e72656c61786174696f6e5f666163746f7294473ff80000000000008c11636f6d62696e65722e737061727369747994473f1a36e2eb1c432d8c16636f6d62696e65722e626e5f7669727475616c5f6273944d00018c14636f6d62696e65722e626e5f6d6f6d656e74756d94473fb999999999999a758c1274696d655f73696e63655f726573746f7265944740568d557a0000008c1774696d6573746570735f73696e63655f726573746f7265944b008c18697465726174696f6e735f73696e63655f726573746f7265944b028c0b7761726d75705f74696d6594473f70f640000000008c0e6578706572696d656e745f746167945819010000355f636f6d62696e65725f626e5f6d6f6d656e74756d3d302e313030302c636f6d62696e65725f626e5f7669727475616c5f62733d3235362c636f6d62696e65725f6e756d5f73746570733d352c636f6d62696e65725f6f75747075745f73697a653d36342c636f6d62696e65725f72656c61786174696f6e5f666163746f723d312e353030302c636f6d62696e65725f73697a653d36342c636f6d62696e65725f73706172736974793d302e303030312c747261696e65725f62617463685f73697a653d3531322c747261696e65725f64656361795f726174653d302e393530302c747261696e65725f64656361795f73746570733d32303030302c747261696e65725f6c6561726e696e675f726174653d302e303035309475682d682e8c056f72646572944b0275628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68127d94682d4e68424b0075628c115f626573745f636865636b706f696e7473945d9468008c0951756575654974656d9493942981947d94288c087072696f7269747994884b024b0287946810680c7562618c0b5f6d656d62657273686970948f9428680c908c0a5f6375725f6f72646572944b0275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"trainable_func_f2we_ZX\",\n  \"trial_id\": \"fddd10a0\",\n  \"config\": {\n    \"trainer.learning_rate\": 0.005,\n    \"trainer.batch_size\": 512,\n    \"trainer.decay_rate\": 0.8,\n    \"trainer.decay_steps\": 500,\n    \"combiner.size\": 8,\n    \"combiner.output_size\": 8,\n    \"combiner.num_steps\": 3,\n    \"combiner.relaxation_factor\": 1.0,\n    \"combiner.sparsity\": 1e-06,\n    \"combiner.bn_virtual_bs\": 1024,\n    \"combiner.bn_momentum\": 0.02\n  },\n  \"local_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt\",\n  \"evaluated_params\": {\n    \"combiner.bn_momentum\": 0.02,\n    \"combiner.bn_virtual_bs\": 1024,\n    \"combiner.num_steps\": 3,\n    \"combiner.output_size\": 8,\n    \"combiner.relaxation_factor\": 1.0,\n    \"combiner.size\": 8,\n    \"combiner.sparsity\": 1e-06,\n    \"trainer.batch_size\": 512,\n    \"trainer.decay_rate\": 0.8,\n    \"trainer.decay_steps\": 500,\n    \"trainer.learning_rate\": 0.005\n  },\n  \"experiment_tag\": \"3_combiner_bn_momentum=0.0200,combiner_bn_virtual_bs=1024,combiner_num_steps=3,combiner_output_size=8,combiner_relaxation_factor=1.0000,combiner_size=8,combiner_sparsity=0.0000,trainer_batch_size=512,trainer_decay_rate=0.8000,trainer_decay_steps=500,trainer_learning_rate=0.0050\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595a6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 1,\n  \"_last_result\": {\n    \"parameters\": \"{\\\"trainer.learning_rate\\\": 0.005, \\\"trainer.batch_size\\\": 512, \\\"trainer.decay_rate\\\": 0.8, \\\"trainer.decay_steps\\\": 500, \\\"combiner.size\\\": 8, \\\"combiner.output_size\\\": 8, \\\"combiner.num_steps\\\": 3, \\\"combiner.relaxation_factor\\\": 1.0, \\\"combiner.sparsity\\\": 1e-06, \\\"combiner.bn_virtual_bs\\\": 1024, \\\"combiner.bn_momentum\\\": 0.02}\",\n    \"metric_score\": 0.9806248545646667,\n    \"training_stats\": \"{\\\"training\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.41980960965156555, 0.1886724829673767, 0.12610362470149994, 0.08308761566877365, 0.07712692767381668], \\\"roc_auc\\\": [0.7787164449691772, 0.9190508127212524, 0.9705900549888611, 0.9869155287742615, 0.9838906526565552], \\\"accuracy\\\": [0.9040622115135193, 0.9057593941688538, 0.9435373544692993, 0.9655849933624268, 0.9720279574394226]}, \\\"combined\\\": {\\\"loss\\\": [0.41981161483704454, 0.18867404351749428, 0.12610492644705573, 0.08308878814023046, 0.0771280116558728]}}, \\\"validation\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.42158612608909607, 0.1907925009727478, 0.14003293216228485, 0.0986025258898735, 0.09832314401865005], \\\"roc_auc\\\": [0.7813661098480225, 0.9182260036468506, 0.9620145559310913, 0.9806248545646667, 0.9752957224845886], \\\"accuracy\\\": [0.9016321301460266, 0.9029554724693298, 0.933722972869873, 0.9564402103424072, 0.9665858149528503]}, \\\"combined\\\": {\\\"loss\\\": [0.42158813078935964, 0.19079402596685213, 0.14003421729489673, 0.09860368910426587, 0.0983242205403485]}}, \\\"test\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.4244043231010437, 0.19957484304904938, 0.13952387869358063, 0.09919699281454086, 0.09547703713178635], \\\"roc_auc\\\": [0.7765635251998901, 0.9156337380409241, 0.9648204445838928, 0.9815257787704468, 0.9767876267433167], \\\"accuracy\\\": [0.8983621001243591, 0.8987481594085693, 0.934814989566803, 0.9573705196380615, 0.9640434384346008]}, \\\"combined\\\": {\\\"loss\\\": [0.42440632814509627, 0.19957630798285209, 0.13952513389756405, 0.09919813912517839, 0.0954780998268916]}}}\",\n    \"eval_stats\": \"{}\",\n    \"trial_id\": \"fddd10a0\",\n    \"trial_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_fddd10a0/\",\n    \"time_this_iter_s\": 11.802548170089722,\n    \"should_checkpoint\": true,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 5,\n    \"experiment_id\": \"e592a995fb4a42d3bb8d2f0a443a09e6\",\n    \"date\": \"2022-06-28_23-33-06\",\n    \"timestamp\": 1656473586,\n    \"time_total_s\": 76.36426997184753,\n    \"pid\": 44861,\n    \"hostname\": \"C02FR8FUMD6R.grubhub.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"trainer.learning_rate\": 0.005,\n      \"trainer.batch_size\": 512,\n      \"trainer.decay_rate\": 0.8,\n      \"trainer.decay_steps\": 500,\n      \"combiner.size\": 8,\n      \"combiner.output_size\": 8,\n      \"combiner.num_steps\": 3,\n      \"combiner.relaxation_factor\": 1.0,\n      \"combiner.sparsity\": 1e-06,\n      \"combiner.bn_virtual_bs\": 1024,\n      \"combiner.bn_momentum\": 0.02\n    },\n    \"time_since_restore\": 76.36426997184753,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 5,\n    \"warmup_time\": 0.005265951156616211,\n    \"experiment_tag\": \"3_combiner_bn_momentum=0.0200,combiner_bn_virtual_bs=1024,combiner_num_steps=3,combiner_output_size=8,combiner_relaxation_factor=1.0000,combiner_size=8,combiner_sparsity=0.0000,trainer_batch_size=512,trainer_decay_rate=0.8000,trainer_decay_steps=500,trainer_learning_rate=0.0050\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1656473586.113837,\n  \"metric_analysis\": {\n    \"metric_score\": {\n      \"max\": 0.9806248545646667,\n      \"min\": 0.7813661098480225,\n      \"avg\": 0.9245712757110596,\n      \"last\": 0.9806248545646667,\n      \"last-5-avg\": 0.9245712757110596,\n      \"last-10-avg\": 0.9245712757110596\n    },\n    \"time_this_iter_s\": {\n      \"max\": 18.55836296081543,\n      \"min\": 11.802548170089722,\n      \"avg\": 15.272853994369507,\n      \"last\": 11.802548170089722,\n      \"last-5-avg\": 15.272853994369507,\n      \"last-10-avg\": 15.272853994369507\n    },\n    \"should_checkpoint\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": 1.0,\n      \"last\": true,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.2,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.2\n    },\n    \"training_iteration\": {\n      \"max\": 5,\n      \"min\": 1,\n      \"avg\": 3.0,\n      \"last\": 5,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    },\n    \"time_total_s\": {\n      \"max\": 76.36426997184753,\n      \"min\": 15.26307201385498,\n      \"avg\": 47.691720533370976,\n      \"last\": 76.36426997184753,\n      \"last-5-avg\": 47.69172053337097,\n      \"last-10-avg\": 47.69172053337097\n    },\n    \"time_since_restore\": {\n      \"max\": 76.36426997184753,\n      \"min\": 15.26307201385498,\n      \"avg\": 47.691720533370976,\n      \"last\": 76.36426997184753,\n      \"last-5-avg\": 47.69172053337097,\n      \"last-10-avg\": 47.69172053337097\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 5,\n      \"min\": 1,\n      \"avg\": 3.0,\n      \"last\": 5,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    },\n    \"warmup_time\": {\n      \"max\": 0.005265951156616211,\n      \"min\": 0.005265951156616211,\n      \"avg\": 0.005265951156616211,\n      \"last\": 0.005265951156616211,\n      \"last-5-avg\": 0.005265951156616211,\n      \"last-10-avg\": 0.005265951156616211\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"metric_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe900f380000000473fed621b80000000473feec8d2c0000000473fef614760000000473fef614760000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe900f380000000473fed621b80000000473feec8d2c0000000473fef614760000000473fef614760000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847402e86b1600000004740328ef0e000000047402d40dac00000004740301d16100000004740279ae798000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847402e86b1600000004740328ef0e000000047402d40dac00000004740301d16100000004740279ae798000000652e\"\n      }\n    },\n    \"should_checkpoint\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288888888888652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288888888888652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b034b044b05652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b05652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847402e86b160000000474040e924c8000000474048395b7800000047405023f340000000474053175033000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847402e86b160000000474040e924c8000000474048395b7800000047405023f340000000474053175033000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847402e86b160000000474040e924c8000000474048395b7800000047405023f340000000474053175033000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847402e86b160000000474040e924c8000000474048395b7800000047405023f340000000474053175033000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b034b044b05652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b05652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f7591c000000000473f7591c000000000473f7591c000000000473f7591c000000000473f7591c000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f7591c000000000473f7591c000000000473f7591c000000000473f7591c000000000473f7591c000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1656473501.5049322,\n  \"logdir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_fddd10a0\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd2024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd3024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": \"trial_fddd10a0\",\n  \"custom_dirname\": \"trial_fddd10a0\",\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": 1,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595d90d0000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d944b018c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0f5f54756e65436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565948c582f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f68797065726f70742f747269616c5f66646464313061302f636865636b706f696e745f3030303030352f948c06726573756c74947d94288c0a706172616d65746572739458370100007b22747261696e65722e6c6561726e696e675f72617465223a20302e3030352c2022747261696e65722e62617463685f73697a65223a203531322c2022747261696e65722e64656361795f72617465223a20302e382c2022747261696e65722e64656361795f7374657073223a203530302c2022636f6d62696e65722e73697a65223a20382c2022636f6d62696e65722e6f75747075745f73697a65223a20382c2022636f6d62696e65722e6e756d5f7374657073223a20332c2022636f6d62696e65722e72656c61786174696f6e5f666163746f72223a20312e302c2022636f6d62696e65722e7370617273697479223a2031652d30362c2022636f6d62696e65722e626e5f7669727475616c5f6273223a20313032342c2022636f6d62696e65722e626e5f6d6f6d656e74756d223a20302e30327d948c0c6d65747269635f73636f726594473fef6147600000008c0e747261696e696e675f73746174739458d10500007b22747261696e696e67223a207b2268617a6172646f7573223a207b226c6f7373223a205b302e34313938303936303936353135363535352c20302e313838363732343832393637333736372c20302e31323631303336323437303134393939342c20302e30383330383736313536363837373336352c20302e30373731323639323736373338313636385d2c2022726f635f617563223a205b302e373738373136343434393639313737322c20302e393139303530383132373231323532342c20302e393730353930303534393838383631312c20302e393836393135353238373734323631352c20302e393833383930363532363536353535325d2c20226163637572616379223a205b302e393034303632323131353133353139332c20302e393035373539333934313638383533382c20302e393433353337333534343639323939332c20302e393635353834393933333632343236382c20302e393732303237393537343339343232365d7d2c2022636f6d62696e6564223a207b226c6f7373223a205b302e34313938313136313438333730343435342c20302e31383836373430343335313734393432382c20302e31323631303439323634343730353537332c20302e30383330383837383831343032333034362c20302e303737313238303131363535383732385d7d7d2c202276616c69646174696f6e223a207b2268617a6172646f7573223a207b226c6f7373223a205b302e34323135383631323630383930393630372c20302e313930373932353030393732373437382c20302e31343030333239333231363232383438352c20302e303938363032353235383839383733352c20302e30393833323331343430313836353030355d2c2022726f635f617563223a205b302e373831333636313039383438303232352c20302e393138323236303033363436383530362c20302e393632303134353535393331303931332c20302e393830363234383534353634363636372c20302e393735323935373232343834353838365d2c20226163637572616379223a205b302e393031363332313330313436303236362c20302e393032393535343732343639333239382c20302e3933333732323937323836393837332c20302e393536343430323130333432343037322c20302e393636353835383134393532383530335d7d2c2022636f6d62696e6564223a207b226c6f7373223a205b302e34323135383831333037383933353936342c20302e31393037393430323539363638353231332c20302e31343030333432313732393438393637332c20302e30393836303336383931303432363538372c20302e303938333234323230353430333438355d7d7d2c202274657374223a207b2268617a6172646f7573223a207b226c6f7373223a205b302e343234343034333233313031303433372c20302e31393935373438343330343930343933382c20302e31333935323338373836393335383036332c20302e30393931393639393238313435343038362c20302e30393534373730333731333137383633355d2c2022726f635f617563223a205b302e373736353633353235313939383930312c20302e393135363333373338303430393234312c20302e393634383230343434353833383932382c20302e393831353235373738373730343436382c20302e393736373837363236373433333136375d2c20226163637572616379223a205b302e383938333632313030313234333539312c20302e383938373438313539343038353639332c20302e3933343831343938393536363830332c20302e393537333730353139363338303631352c20302e393634303433343338343334363030385d7d2c2022636f6d62696e6564223a207b226c6f7373223a205b302e34323434303633323831343530393632372c20302e31393935373633303739383238353230392c20302e31333935323531333338393735363430352c20302e30393931393831333931323531373833392c20302e303935343738303939383236383931365d7d7d7d948c0a6576616c5f7374617473948c027b7d948c08747269616c5f6964948c086664646431306130948c09747269616c5f646972948c462f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f68797065726f70742f747269616c5f66646464313061302f948c1074696d655f746869735f697465725f73944740279ae7980000008c1173686f756c645f636865636b706f696e7494888c04646f6e6594888c0f74696d6573746570735f746f74616c944e8c0e657069736f6465735f746f74616c944e68084b058c0d6578706572696d656e745f6964948c206535393261393935666234613432643362623864326630613434336130396536948c0464617465948c13323032322d30362d32385f32332d33332d3036948c0974696d657374616d70944af2c7bb628c0c74696d655f746f74616c5f73944740531750330000008c03706964944d3daf8c08686f73746e616d65948c1a43303246523846554d4436522e677275626875622e6c6f63616c948c076e6f64655f6970948c093132372e302e302e31948c06636f6e666967947d94288c15747261696e65722e6c6561726e696e675f7261746594473f747ae147ae147b8c12747261696e65722e62617463685f73697a65944d00028c12747261696e65722e64656361795f7261746594473fe999999999999a8c13747261696e65722e64656361795f7374657073944df4018c0d636f6d62696e65722e73697a65944b088c14636f6d62696e65722e6f75747075745f73697a65944b088c12636f6d62696e65722e6e756d5f7374657073944b038c1a636f6d62696e65722e72656c61786174696f6e5f666163746f7294473ff00000000000008c11636f6d62696e65722e737061727369747994473eb0c6f7a0b5ed8d8c16636f6d62696e65722e626e5f7669727475616c5f6273944d00048c14636f6d62696e65722e626e5f6d6f6d656e74756d94473f947ae147ae147b758c1274696d655f73696e63655f726573746f7265944740531750330000008c1774696d6573746570735f73696e63655f726573746f7265944b008c18697465726174696f6e735f73696e63655f726573746f7265944b058c0b7761726d75705f74696d6594473f7591c0000000008c0e6578706572696d656e745f746167945816010000335f636f6d62696e65725f626e5f6d6f6d656e74756d3d302e303230302c636f6d62696e65725f626e5f7669727475616c5f62733d313032342c636f6d62696e65725f6e756d5f73746570733d332c636f6d62696e65725f6f75747075745f73697a653d382c636f6d62696e65725f72656c61786174696f6e5f666163746f723d312e303030302c636f6d62696e65725f73697a653d382c636f6d62696e65725f73706172736974793d302e303030302c747261696e65725f62617463685f73697a653d3531322c747261696e65725f64656361795f726174653d302e383030302c747261696e65725f64656361795f73746570733d3530302c747261696e65725f6c6561726e696e675f726174653d302e303035309475682d682e8c056f72646572944b0575628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68127d94682d4e68424b0075628c115f626573745f636865636b706f696e7473945d9468008c0951756575654974656d9493942981947d94288c087072696f7269747994884b054b0587946810680c7562618c0b5f6d656d62657273686970948f9428680c908c0a5f6375725f6f72646572944b0575622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"trainable_func_f2we_ZX\",\n  \"trial_id\": \"fdf24786\",\n  \"config\": {\n    \"trainer.learning_rate\": 0.01,\n    \"trainer.batch_size\": 256,\n    \"trainer.decay_rate\": 0.9,\n    \"trainer.decay_steps\": 10000,\n    \"combiner.size\": 64,\n    \"combiner.output_size\": 24,\n    \"combiner.num_steps\": 7,\n    \"combiner.relaxation_factor\": 1.5,\n    \"combiner.sparsity\": 0.0,\n    \"combiner.bn_virtual_bs\": 4096,\n    \"combiner.bn_momentum\": 0.1\n  },\n  \"local_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt\",\n  \"evaluated_params\": {\n    \"combiner.bn_momentum\": 0.1,\n    \"combiner.bn_virtual_bs\": 4096,\n    \"combiner.num_steps\": 7,\n    \"combiner.output_size\": 24,\n    \"combiner.relaxation_factor\": 1.5,\n    \"combiner.size\": 64,\n    \"combiner.sparsity\": 0.0,\n    \"trainer.batch_size\": 256,\n    \"trainer.decay_rate\": 0.9,\n    \"trainer.decay_steps\": 10000,\n    \"trainer.learning_rate\": 0.01\n  },\n  \"experiment_tag\": \"8_combiner_bn_momentum=0.1000,combiner_bn_virtual_bs=4096,combiner_num_steps=7,combiner_output_size=24,combiner_relaxation_factor=1.5000,combiner_size=64,combiner_sparsity=0.0000,trainer_batch_size=256,trainer_decay_rate=0.9000,trainer_decay_steps=10000,trainer_learning_rate=0.0100\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595a6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 1,\n  \"_last_result\": {\n    \"parameters\": \"{\\\"trainer.learning_rate\\\": 0.01, \\\"trainer.batch_size\\\": 256, \\\"trainer.decay_rate\\\": 0.9, \\\"trainer.decay_steps\\\": 10000, \\\"combiner.size\\\": 64, \\\"combiner.output_size\\\": 24, \\\"combiner.num_steps\\\": 7, \\\"combiner.relaxation_factor\\\": 1.5, \\\"combiner.sparsity\\\": 0.0, \\\"combiner.bn_virtual_bs\\\": 4096, \\\"combiner.bn_momentum\\\": 0.1}\",\n    \"metric_score\": 0.915641725063324,\n    \"training_stats\": \"{\\\"training\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.24633096158504486, 0.18705104291439056], \\\"roc_auc\\\": [0.8395981192588806, 0.9189009666442871], \\\"accuracy\\\": [0.9016422033309937, 0.9098137617111206]}, \\\"combined\\\": {\\\"loss\\\": [0.24633096158504486, 0.18705104291439056]}}, \\\"validation\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.2513847053050995, 0.19371657073497772], \\\"roc_auc\\\": [0.8392467498779297, 0.915641725063324], \\\"accuracy\\\": [0.8976621031761169, 0.9048301577568054]}, \\\"combined\\\": {\\\"loss\\\": [0.2513847053050995, 0.19371657073497772]}}, \\\"test\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.25711479783058167, 0.19435198605060577], \\\"roc_auc\\\": [0.8384526968002319, 0.9176055788993835], \\\"accuracy\\\": [0.8954944014549255, 0.9047592878341675]}, \\\"combined\\\": {\\\"loss\\\": [0.25711479783058167, 0.19435198605060577]}}}\",\n    \"eval_stats\": \"{}\",\n    \"trial_id\": \"fdf24786\",\n    \"trial_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_fdf24786/\",\n    \"time_this_iter_s\": 38.705079078674316,\n    \"should_checkpoint\": true,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 2,\n    \"experiment_id\": \"c7262a9bd0c7438dbd8728dd17b940de\",\n    \"date\": \"2022-06-28_23-33-34\",\n    \"timestamp\": 1656473614,\n    \"time_total_s\": 104.38730692863464,\n    \"pid\": 44874,\n    \"hostname\": \"C02FR8FUMD6R.grubhub.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"trainer.learning_rate\": 0.01,\n      \"trainer.batch_size\": 256,\n      \"trainer.decay_rate\": 0.9,\n      \"trainer.decay_steps\": 10000,\n      \"combiner.size\": 64,\n      \"combiner.output_size\": 24,\n      \"combiner.num_steps\": 7,\n      \"combiner.relaxation_factor\": 1.5,\n      \"combiner.sparsity\": 0.0,\n      \"combiner.bn_virtual_bs\": 4096,\n      \"combiner.bn_momentum\": 0.1\n    },\n    \"time_since_restore\": 104.38730692863464,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 2,\n    \"warmup_time\": 0.004734992980957031,\n    \"experiment_tag\": \"8_combiner_bn_momentum=0.1000,combiner_bn_virtual_bs=4096,combiner_num_steps=7,combiner_output_size=24,combiner_relaxation_factor=1.5000,combiner_size=64,combiner_sparsity=0.0000,trainer_batch_size=256,trainer_decay_rate=0.9000,trainer_decay_steps=10000,trainer_learning_rate=0.0100\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1656473614.0287528,\n  \"metric_analysis\": {\n    \"metric_score\": {\n      \"max\": 0.915641725063324,\n      \"min\": 0.8392467498779297,\n      \"avg\": 0.8774442374706268,\n      \"last\": 0.915641725063324,\n      \"last-5-avg\": 0.8774442374706268,\n      \"last-10-avg\": 0.8774442374706268\n    },\n    \"time_this_iter_s\": {\n      \"max\": 65.68222784996033,\n      \"min\": 38.705079078674316,\n      \"avg\": 52.19365346431732,\n      \"last\": 38.705079078674316,\n      \"last-5-avg\": 52.19365346431732,\n      \"last-10-avg\": 52.19365346431732\n    },\n    \"should_checkpoint\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": 1.0,\n      \"last\": true,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_total_s\": {\n      \"max\": 104.38730692863464,\n      \"min\": 65.68222784996033,\n      \"avg\": 85.03476738929749,\n      \"last\": 104.38730692863464,\n      \"last-5-avg\": 85.03476738929749,\n      \"last-10-avg\": 85.03476738929749\n    },\n    \"time_since_restore\": {\n      \"max\": 104.38730692863464,\n      \"min\": 65.68222784996033,\n      \"avg\": 85.03476738929749,\n      \"last\": 104.38730692863464,\n      \"last-5-avg\": 85.03476738929749,\n      \"last-10-avg\": 85.03476738929749\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.004734992980957031,\n      \"min\": 0.004734992980957031,\n      \"avg\": 0.004734992980957031,\n      \"last\": 0.004734992980957031,\n      \"last-5-avg\": 0.004734992980957031,\n      \"last-10-avg\": 0.004734992980957031\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"metric_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473feadb1c00000000473fed4cefe0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473feadb1c00000000473fed4cefe0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740506ba99f0000004740435a4008000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740506ba99f0000004740435a4008000000652e\"\n      }\n    },\n    \"should_checkpoint\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288888652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288888652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740506ba99f00000047405a18c9a3000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740506ba99f00000047405a18c9a3000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740506ba99f00000047405a18c9a3000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740506ba99f00000047405a18c9a3000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f73650000000000473f73650000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f73650000000000473f73650000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1656473501.653753,\n  \"logdir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_fdf24786\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd2024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd3024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": \"trial_fdf24786\",\n  \"custom_dirname\": \"trial_fdf24786\",\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": 1,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"trainable_func_f2we_ZX\",\n  \"trial_id\": \"fdfc11e4\",\n  \"config\": {\n    \"trainer.learning_rate\": 0.02,\n    \"trainer.batch_size\": 256,\n    \"trainer.decay_rate\": 0.9,\n    \"trainer.decay_steps\": 8000,\n    \"combiner.size\": 24,\n    \"combiner.output_size\": 16,\n    \"combiner.num_steps\": 9,\n    \"combiner.relaxation_factor\": 1.0,\n    \"combiner.sparsity\": 0.001,\n    \"combiner.bn_virtual_bs\": 512,\n    \"combiner.bn_momentum\": 0.2\n  },\n  \"local_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt\",\n  \"evaluated_params\": {\n    \"combiner.bn_momentum\": 0.2,\n    \"combiner.bn_virtual_bs\": 512,\n    \"combiner.num_steps\": 9,\n    \"combiner.output_size\": 16,\n    \"combiner.relaxation_factor\": 1.0,\n    \"combiner.size\": 24,\n    \"combiner.sparsity\": 0.001,\n    \"trainer.batch_size\": 256,\n    \"trainer.decay_rate\": 0.9,\n    \"trainer.decay_steps\": 8000,\n    \"trainer.learning_rate\": 0.02\n  },\n  \"experiment_tag\": \"10_combiner_bn_momentum=0.2000,combiner_bn_virtual_bs=512,combiner_num_steps=9,combiner_output_size=16,combiner_relaxation_factor=1.0000,combiner_size=24,combiner_sparsity=0.0010,trainer_batch_size=256,trainer_decay_rate=0.9000,trainer_decay_steps=8000,trainer_learning_rate=0.0200\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595a6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 1,\n  \"_last_result\": {\n    \"parameters\": \"{\\\"trainer.learning_rate\\\": 0.02, \\\"trainer.batch_size\\\": 256, \\\"trainer.decay_rate\\\": 0.9, \\\"trainer.decay_steps\\\": 8000, \\\"combiner.size\\\": 24, \\\"combiner.output_size\\\": 16, \\\"combiner.num_steps\\\": 9, \\\"combiner.relaxation_factor\\\": 1.0, \\\"combiner.sparsity\\\": 0.001, \\\"combiner.bn_virtual_bs\\\": 512, \\\"combiner.bn_momentum\\\": 0.2}\",\n    \"metric_score\": 0.9315594434738159,\n    \"training_stats\": \"{\\\"training\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.24986429512500763, 0.16342276334762573], \\\"roc_auc\\\": [0.8686361312866211, 0.9398977160453796], \\\"accuracy\\\": [0.8980592489242554, 0.9267698526382446]}, \\\"combined\\\": {\\\"loss\\\": [0.25042096292600036, 0.163866263726959]}}, \\\"validation\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.257843554019928, 0.17657682299613953], \\\"roc_auc\\\": [0.8640846014022827, 0.9315594434738159], \\\"accuracy\\\": [0.8992059826850891, 0.9178429841995239]}, \\\"combined\\\": {\\\"loss\\\": [0.2584000410279259, 0.17701126297470182]}}, \\\"test\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.254751056432724, 0.17047536373138428], \\\"roc_auc\\\": [0.8704236149787903, 0.9401657581329346], \\\"accuracy\\\": [0.8951635360717773, 0.9196492433547974]}, \\\"combined\\\": {\\\"loss\\\": [0.2553080036304891, 0.17089474911335856]}}}\",\n    \"eval_stats\": \"{}\",\n    \"trial_id\": \"fdfc11e4\",\n    \"trial_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_fdfc11e4/\",\n    \"time_this_iter_s\": 39.492101192474365,\n    \"should_checkpoint\": true,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 2,\n    \"experiment_id\": \"c33c2061adb44bdca7954f9f3748c656\",\n    \"date\": \"2022-06-28_23-33-31\",\n    \"timestamp\": 1656473611,\n    \"time_total_s\": 101.3931188583374,\n    \"pid\": 44879,\n    \"hostname\": \"C02FR8FUMD6R.grubhub.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"trainer.learning_rate\": 0.02,\n      \"trainer.batch_size\": 256,\n      \"trainer.decay_rate\": 0.9,\n      \"trainer.decay_steps\": 8000,\n      \"combiner.size\": 24,\n      \"combiner.output_size\": 16,\n      \"combiner.num_steps\": 9,\n      \"combiner.relaxation_factor\": 1.0,\n      \"combiner.sparsity\": 0.001,\n      \"combiner.bn_virtual_bs\": 512,\n      \"combiner.bn_momentum\": 0.2\n    },\n    \"time_since_restore\": 101.3931188583374,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 2,\n    \"warmup_time\": 0.005439043045043945,\n    \"experiment_tag\": \"10_combiner_bn_momentum=0.2000,combiner_bn_virtual_bs=512,combiner_num_steps=9,combiner_output_size=16,combiner_relaxation_factor=1.0000,combiner_size=24,combiner_sparsity=0.0010,trainer_batch_size=256,trainer_decay_rate=0.9000,trainer_decay_steps=8000,trainer_learning_rate=0.0200\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1656473611.108373,\n  \"metric_analysis\": {\n    \"metric_score\": {\n      \"max\": 0.9315594434738159,\n      \"min\": 0.8640846014022827,\n      \"avg\": 0.8978220224380493,\n      \"last\": 0.9315594434738159,\n      \"last-5-avg\": 0.8978220224380493,\n      \"last-10-avg\": 0.8978220224380493\n    },\n    \"time_this_iter_s\": {\n      \"max\": 61.90101766586304,\n      \"min\": 39.492101192474365,\n      \"avg\": 50.6965594291687,\n      \"last\": 39.492101192474365,\n      \"last-5-avg\": 50.6965594291687,\n      \"last-10-avg\": 50.6965594291687\n    },\n    \"should_checkpoint\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": 1.0,\n      \"last\": true,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_total_s\": {\n      \"max\": 101.3931188583374,\n      \"min\": 61.90101766586304,\n      \"avg\": 81.64706826210022,\n      \"last\": 101.3931188583374,\n      \"last-5-avg\": 81.64706826210022,\n      \"last-10-avg\": 81.64706826210022\n    },\n    \"time_since_restore\": {\n      \"max\": 101.3931188583374,\n      \"min\": 61.90101766586304,\n      \"avg\": 81.64706826210022,\n      \"last\": 101.3931188583374,\n      \"last-5-avg\": 81.64706826210022,\n      \"last-10-avg\": 81.64706826210022\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.005439043045043945,\n      \"min\": 0.005439043045043945,\n      \"avg\": 0.005439043045043945,\n      \"last\": 0.005439043045043945,\n      \"last-5-avg\": 0.005439043045043945,\n      \"last-10-avg\": 0.005439043045043945\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"metric_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473feba694c0000000473fedcf55c0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473feba694c0000000473fedcf55c0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404ef3548c000000474043befd2c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404ef3548c000000474043befd2c000000652e\"\n      }\n    },\n    \"should_checkpoint\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288888652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288888652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404ef3548c0000004740595928dc000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404ef3548c0000004740595928dc000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404ef3548c0000004740595928dc000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404ef3548c0000004740595928dc000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f76474000000000473f76474000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f76474000000000473f76474000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1656473501.7156138,\n  \"logdir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_fdfc11e4\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd2024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd3024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": \"trial_fdfc11e4\",\n  \"custom_dirname\": \"trial_fdfc11e4\",\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": 1,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"trainable_func_f2we_ZX\",\n  \"trial_id\": \"fdee2ad4\",\n  \"config\": {\n    \"trainer.learning_rate\": 0.025,\n    \"trainer.batch_size\": 1024,\n    \"trainer.decay_rate\": 0.95,\n    \"trainer.decay_steps\": 10000,\n    \"combiner.size\": 8,\n    \"combiner.output_size\": 32,\n    \"combiner.num_steps\": 5,\n    \"combiner.relaxation_factor\": 2.0,\n    \"combiner.sparsity\": 0.0,\n    \"combiner.bn_virtual_bs\": 512,\n    \"combiner.bn_momentum\": 0.4\n  },\n  \"local_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt\",\n  \"evaluated_params\": {\n    \"combiner.bn_momentum\": 0.4,\n    \"combiner.bn_virtual_bs\": 512,\n    \"combiner.num_steps\": 5,\n    \"combiner.output_size\": 32,\n    \"combiner.relaxation_factor\": 2.0,\n    \"combiner.size\": 8,\n    \"combiner.sparsity\": 0.0,\n    \"trainer.batch_size\": 1024,\n    \"trainer.decay_rate\": 0.95,\n    \"trainer.decay_steps\": 10000,\n    \"trainer.learning_rate\": 0.025\n  },\n  \"experiment_tag\": \"7_combiner_bn_momentum=0.4000,combiner_bn_virtual_bs=512,combiner_num_steps=5,combiner_output_size=32,combiner_relaxation_factor=2.0000,combiner_size=8,combiner_sparsity=0.0000,trainer_batch_size=1024,trainer_decay_rate=0.9500,trainer_decay_steps=10000,trainer_learning_rate=0.0250\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595a6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 1,\n  \"_last_result\": {\n    \"parameters\": \"{\\\"trainer.learning_rate\\\": 0.025, \\\"trainer.batch_size\\\": 1024, \\\"trainer.decay_rate\\\": 0.95, \\\"trainer.decay_steps\\\": 10000, \\\"combiner.size\\\": 8, \\\"combiner.output_size\\\": 32, \\\"combiner.num_steps\\\": 5, \\\"combiner.relaxation_factor\\\": 2.0, \\\"combiner.sparsity\\\": 0.0, \\\"combiner.bn_virtual_bs\\\": 512, \\\"combiner.bn_momentum\\\": 0.4}\",\n    \"metric_score\": 0.9546341300010681,\n    \"training_stats\": \"{\\\"training\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.30893632769584656, 0.19582395255565643, 0.1541995108127594], \\\"roc_auc\\\": [0.8242508172988892, 0.9065142869949341, 0.9600653052330017], \\\"accuracy\\\": [0.867415726184845, 0.9018150568008423, 0.9390272498130798]}, \\\"combined\\\": {\\\"loss\\\": [0.30893632769584656, 0.19582395255565643, 0.1541995108127594]}}, \\\"validation\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.30453622341156006, 0.19444483518600464, 0.16034649312496185], \\\"roc_auc\\\": [0.8434162735939026, 0.9087686538696289, 0.9546341300010681], \\\"accuracy\\\": [0.8699823617935181, 0.8995368480682373, 0.9335024356842041]}, \\\"combined\\\": {\\\"loss\\\": [0.30453622341156006, 0.19444483518600464, 0.16034649312496185]}}, \\\"test\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.3077892065048218, 0.1983390897512436, 0.16003578901290894], \\\"roc_auc\\\": [0.823287844657898, 0.9091353416442871, 0.9562329649925232], \\\"accuracy\\\": [0.8637291193008423, 0.8973143100738525, 0.9316163659095764]}, \\\"combined\\\": {\\\"loss\\\": [0.3077892065048218, 0.1983390897512436, 0.16003578901290894]}}}\",\n    \"eval_stats\": \"{}\",\n    \"trial_id\": \"fdee2ad4\",\n    \"trial_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_fdee2ad4/\",\n    \"time_this_iter_s\": 22.235005140304565,\n    \"should_checkpoint\": true,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 3,\n    \"experiment_id\": \"1d2c97766364458aaf9bbeb3f2b71d97\",\n    \"date\": \"2022-06-28_23-33-03\",\n    \"timestamp\": 1656473583,\n    \"time_total_s\": 74.10681295394897,\n    \"pid\": 44869,\n    \"hostname\": \"C02FR8FUMD6R.grubhub.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"trainer.learning_rate\": 0.025,\n      \"trainer.batch_size\": 1024,\n      \"trainer.decay_rate\": 0.95,\n      \"trainer.decay_steps\": 10000,\n      \"combiner.size\": 8,\n      \"combiner.output_size\": 32,\n      \"combiner.num_steps\": 5,\n      \"combiner.relaxation_factor\": 2.0,\n      \"combiner.sparsity\": 0.0,\n      \"combiner.bn_virtual_bs\": 512,\n      \"combiner.bn_momentum\": 0.4\n    },\n    \"time_since_restore\": 74.10681295394897,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 3,\n    \"warmup_time\": 0.003423929214477539,\n    \"experiment_tag\": \"7_combiner_bn_momentum=0.4000,combiner_bn_virtual_bs=512,combiner_num_steps=5,combiner_output_size=32,combiner_relaxation_factor=2.0000,combiner_size=8,combiner_sparsity=0.0000,trainer_batch_size=1024,trainer_decay_rate=0.9500,trainer_decay_steps=10000,trainer_learning_rate=0.0250\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1656473583.689395,\n  \"metric_analysis\": {\n    \"metric_score\": {\n      \"max\": 0.9546341300010681,\n      \"min\": 0.8434162735939026,\n      \"avg\": 0.9022730191548665,\n      \"last\": 0.9546341300010681,\n      \"last-5-avg\": 0.9022730191548666,\n      \"last-10-avg\": 0.9022730191548666\n    },\n    \"time_this_iter_s\": {\n      \"max\": 26.276012897491455,\n      \"min\": 22.235005140304565,\n      \"avg\": 24.702270984649658,\n      \"last\": 22.235005140304565,\n      \"last-5-avg\": 24.702270984649658,\n      \"last-10-avg\": 24.702270984649658\n    },\n    \"should_checkpoint\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": 1.0,\n      \"last\": true,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.3333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.3333333333333333,\n      \"last-10-avg\": 0.3333333333333333\n    },\n    \"training_iteration\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"time_total_s\": {\n      \"max\": 74.10681295394897,\n      \"min\": 26.276012897491455,\n      \"avg\": 50.751544555028275,\n      \"last\": 74.10681295394897,\n      \"last-5-avg\": 50.75154455502828,\n      \"last-10-avg\": 50.75154455502828\n    },\n    \"time_since_restore\": {\n      \"max\": 74.10681295394897,\n      \"min\": 26.276012897491455,\n      \"avg\": 50.751544555028275,\n      \"last\": 74.10681295394897,\n      \"last-5-avg\": 50.75154455502828,\n      \"last-10-avg\": 50.75154455502828\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"warmup_time\": {\n      \"max\": 0.003423929214477539,\n      \"min\": 0.003423929214477539,\n      \"avg\": 0.003423929214477539,\n      \"last\": 0.003423929214477539,\n      \"last-5-avg\": 0.003423929214477539,\n      \"last-10-avg\": 0.003423929214477539\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"metric_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473feafd4420000000473fed14a200000000473fee8c5ce0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473feafd4420000000473fed14a200000000473fee8c5ce0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403a46a8c80000004740399886040000004740363c294c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403a46a8c80000004740399886040000004740363c294c000000652e\"\n      }\n    },\n    \"should_checkpoint\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428888888652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428888888652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403a46a8c8000000474049ef976600000047405286d606000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403a46a8c8000000474049ef976600000047405286d606000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403a46a8c8000000474049ef976600000047405286d606000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403a46a8c8000000474049ef976600000047405286d606000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f6c0c8000000000473f6c0c8000000000473f6c0c8000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f6c0c8000000000473f6c0c8000000000473f6c0c8000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1656473501.621314,\n  \"logdir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_fdee2ad4\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd2024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd3024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": \"trial_fdee2ad4\",\n  \"custom_dirname\": \"trial_fdee2ad4\",\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": 1,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f20b0000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d944b018c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0f5f54756e65436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565948c582f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f68797065726f70742f747269616c5f66646565326164342f636865636b706f696e745f3030303030332f948c06726573756c74947d94288c0a706172616d65746572739458380100007b22747261696e65722e6c6561726e696e675f72617465223a20302e3032352c2022747261696e65722e62617463685f73697a65223a20313032342c2022747261696e65722e64656361795f72617465223a20302e39352c2022747261696e65722e64656361795f7374657073223a2031303030302c2022636f6d62696e65722e73697a65223a20382c2022636f6d62696e65722e6f75747075745f73697a65223a2033322c2022636f6d62696e65722e6e756d5f7374657073223a20352c2022636f6d62696e65722e72656c61786174696f6e5f666163746f72223a20322e302c2022636f6d62696e65722e7370617273697479223a20302e302c2022636f6d62696e65722e626e5f7669727475616c5f6273223a203531322c2022636f6d62696e65722e626e5f6d6f6d656e74756d223a20302e347d948c0c6d65747269635f73636f726594473fee8c5ce00000008c0e747261696e696e675f73746174739458e60300007b22747261696e696e67223a207b2268617a6172646f7573223a207b226c6f7373223a205b302e33303839333633323736393538343635362c20302e31393538323339353235353536353634332c20302e313534313939353130383132373539345d2c2022726f635f617563223a205b302e383234323530383137323938383839322c20302e393036353134323836393934393334312c20302e393630303635333035323333303031375d2c20226163637572616379223a205b302e3836373431353732363138343834352c20302e393031383135303536383030383432332c20302e393339303237323439383133303739385d7d2c2022636f6d62696e6564223a207b226c6f7373223a205b302e33303839333633323736393538343635362c20302e31393538323339353235353536353634332c20302e313534313939353130383132373539345d7d7d2c202276616c69646174696f6e223a207b2268617a6172646f7573223a207b226c6f7373223a205b302e33303435333632323334313135363030362c20302e31393434343438333531383630303436342c20302e31363033343634393331323439363138355d2c2022726f635f617563223a205b302e383433343136323733353933393032362c20302e393038373638363533383639363238392c20302e393534363334313330303031303638315d2c20226163637572616379223a205b302e383639393832333631373933353138312c20302e383939353336383438303638323337332c20302e393333353032343335363834323034315d7d2c2022636f6d62696e6564223a207b226c6f7373223a205b302e33303435333632323334313135363030362c20302e31393434343438333531383630303436342c20302e31363033343634393331323439363138355d7d7d2c202274657374223a207b2268617a6172646f7573223a207b226c6f7373223a205b302e333037373839323036353034383231382c20302e313938333339303839373531323433362c20302e31363030333537383930313239303839345d2c2022726f635f617563223a205b302e3832333238373834343635373839382c20302e393039313335333431363434323837312c20302e393536323332393634393932353233325d2c20226163637572616379223a205b302e383633373239313139333030383432332c20302e383937333134333130303733383532352c20302e393331363136333635393039353736345d7d2c2022636f6d62696e6564223a207b226c6f7373223a205b302e333037373839323036353034383231382c20302e313938333339303839373531323433362c20302e31363030333537383930313239303839345d7d7d7d948c0a6576616c5f7374617473948c027b7d948c08747269616c5f6964948c086664656532616434948c09747269616c5f646972948c462f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f68797065726f70742f747269616c5f66646565326164342f948c1074696d655f746869735f697465725f73944740363c294c0000008c1173686f756c645f636865636b706f696e7494888c04646f6e6594888c0f74696d6573746570735f746f74616c944e8c0e657069736f6465735f746f74616c944e68084b038c0d6578706572696d656e745f6964948c203164326339373736363336343435386161663962626562336632623731643937948c0464617465948c13323032322d30362d32385f32332d33332d3033948c0974696d657374616d70944aefc7bb628c0c74696d655f746f74616c5f739447405286d6060000008c03706964944d45af8c08686f73746e616d65948c1a43303246523846554d4436522e677275626875622e6c6f63616c948c076e6f64655f6970948c093132372e302e302e31948c06636f6e666967947d94288c15747261696e65722e6c6561726e696e675f7261746594473f9999999999999a8c12747261696e65722e62617463685f73697a65944d00048c12747261696e65722e64656361795f7261746594473fee6666666666668c13747261696e65722e64656361795f7374657073944d10278c0d636f6d62696e65722e73697a65944b088c14636f6d62696e65722e6f75747075745f73697a65944b208c12636f6d62696e65722e6e756d5f7374657073944b058c1a636f6d62696e65722e72656c61786174696f6e5f666163746f72944740000000000000008c11636f6d62696e65722e7370617273697479944700000000000000008c16636f6d62696e65722e626e5f7669727475616c5f6273944d00028c14636f6d62696e65722e626e5f6d6f6d656e74756d94473fd999999999999a758c1274696d655f73696e63655f726573746f72659447405286d6060000008c1774696d6573746570735f73696e63655f726573746f7265944b008c18697465726174696f6e735f73696e63655f726573746f7265944b038c0b7761726d75705f74696d6594473f6c0c80000000008c0e6578706572696d656e745f746167945819010000375f636f6d62696e65725f626e5f6d6f6d656e74756d3d302e343030302c636f6d62696e65725f626e5f7669727475616c5f62733d3531322c636f6d62696e65725f6e756d5f73746570733d352c636f6d62696e65725f6f75747075745f73697a653d33322c636f6d62696e65725f72656c61786174696f6e5f666163746f723d322e303030302c636f6d62696e65725f73697a653d382c636f6d62696e65725f73706172736974793d302e303030302c747261696e65725f62617463685f73697a653d313032342c747261696e65725f64656361795f726174653d302e393530302c747261696e65725f64656361795f73746570733d31303030302c747261696e65725f6c6561726e696e675f726174653d302e303235309475682d682e8c056f72646572944b0375628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68127d94682d4e68424b0075628c115f626573745f636865636b706f696e7473945d9468008c0951756575654974656d9493942981947d94288c087072696f7269747994884b034b0387946810680c7562618c0b5f6d656d62657273686970948f9428680c908c0a5f6375725f6f72646572944b0375622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"trainable_func_f2we_ZX\",\n  \"trial_id\": \"fde0797a\",\n  \"config\": {\n    \"trainer.learning_rate\": 0.01,\n    \"trainer.batch_size\": 256,\n    \"trainer.decay_rate\": 0.95,\n    \"trainer.decay_steps\": 20000,\n    \"combiner.size\": 8,\n    \"combiner.output_size\": 24,\n    \"combiner.num_steps\": 7,\n    \"combiner.relaxation_factor\": 2.0,\n    \"combiner.sparsity\": 0.001,\n    \"combiner.bn_virtual_bs\": 1024,\n    \"combiner.bn_momentum\": 0.2\n  },\n  \"local_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt\",\n  \"evaluated_params\": {\n    \"combiner.bn_momentum\": 0.2,\n    \"combiner.bn_virtual_bs\": 1024,\n    \"combiner.num_steps\": 7,\n    \"combiner.output_size\": 24,\n    \"combiner.relaxation_factor\": 2.0,\n    \"combiner.size\": 8,\n    \"combiner.sparsity\": 0.001,\n    \"trainer.batch_size\": 256,\n    \"trainer.decay_rate\": 0.95,\n    \"trainer.decay_steps\": 20000,\n    \"trainer.learning_rate\": 0.01\n  },\n  \"experiment_tag\": \"4_combiner_bn_momentum=0.2000,combiner_bn_virtual_bs=1024,combiner_num_steps=7,combiner_output_size=24,combiner_relaxation_factor=2.0000,combiner_size=8,combiner_sparsity=0.0010,trainer_batch_size=256,trainer_decay_rate=0.9500,trainer_decay_steps=20000,trainer_learning_rate=0.0100\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595a6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 1,\n  \"_last_result\": {\n    \"parameters\": \"{\\\"trainer.learning_rate\\\": 0.01, \\\"trainer.batch_size\\\": 256, \\\"trainer.decay_rate\\\": 0.95, \\\"trainer.decay_steps\\\": 20000, \\\"combiner.size\\\": 8, \\\"combiner.output_size\\\": 24, \\\"combiner.num_steps\\\": 7, \\\"combiner.relaxation_factor\\\": 2.0, \\\"combiner.sparsity\\\": 0.001, \\\"combiner.bn_virtual_bs\\\": 1024, \\\"combiner.bn_momentum\\\": 0.2}\",\n    \"metric_score\": 0.9181011915206909,\n    \"training_stats\": \"{\\\"training\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.33140063285827637, 0.1817169189453125], \\\"roc_auc\\\": [0.7578039169311523, 0.9262746572494507], \\\"accuracy\\\": [0.9040465354919434, 0.9124380946159363]}, \\\"combined\\\": {\\\"loss\\\": [0.3316989227896556, 0.18193603461259045]}}, \\\"validation\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.3332042098045349, 0.1913660317659378], \\\"roc_auc\\\": [0.763691246509552, 0.9181011915206909], \\\"accuracy\\\": [0.9016321301460266, 0.9084693193435669]}, \\\"combined\\\": {\\\"loss\\\": [0.33350243273889646, 0.1915788106562104]}}, \\\"test\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.3458561599254608, 0.19425998628139496], \\\"roc_auc\\\": [0.757211446762085, 0.9187569618225098], \\\"accuracy\\\": [0.8983621001243591, 0.9047041535377502]}, \\\"combined\\\": {\\\"loss\\\": [0.3461546221515164, 0.19446226255968213]}}}\",\n    \"eval_stats\": \"{}\",\n    \"trial_id\": \"fde0797a\",\n    \"trial_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_fde0797a/\",\n    \"time_this_iter_s\": 35.7854540348053,\n    \"should_checkpoint\": true,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 2,\n    \"experiment_id\": \"03a44685eb364e2894afad7518359d73\",\n    \"date\": \"2022-06-28_23-33-10\",\n    \"timestamp\": 1656473590,\n    \"time_total_s\": 80.76773285865784,\n    \"pid\": 44862,\n    \"hostname\": \"C02FR8FUMD6R.grubhub.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"trainer.learning_rate\": 0.01,\n      \"trainer.batch_size\": 256,\n      \"trainer.decay_rate\": 0.95,\n      \"trainer.decay_steps\": 20000,\n      \"combiner.size\": 8,\n      \"combiner.output_size\": 24,\n      \"combiner.num_steps\": 7,\n      \"combiner.relaxation_factor\": 2.0,\n      \"combiner.sparsity\": 0.001,\n      \"combiner.bn_virtual_bs\": 1024,\n      \"combiner.bn_momentum\": 0.2\n    },\n    \"time_since_restore\": 80.76773285865784,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 2,\n    \"warmup_time\": 0.00449371337890625,\n    \"experiment_tag\": \"4_combiner_bn_momentum=0.2000,combiner_bn_virtual_bs=1024,combiner_num_steps=7,combiner_output_size=24,combiner_relaxation_factor=2.0000,combiner_size=8,combiner_sparsity=0.0010,trainer_batch_size=256,trainer_decay_rate=0.9500,trainer_decay_steps=20000,trainer_learning_rate=0.0100\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1656473590.351947,\n  \"metric_analysis\": {\n    \"metric_score\": {\n      \"max\": 0.9181011915206909,\n      \"min\": 0.763691246509552,\n      \"avg\": 0.8408962190151215,\n      \"last\": 0.9181011915206909,\n      \"last-5-avg\": 0.8408962190151215,\n      \"last-10-avg\": 0.8408962190151215\n    },\n    \"time_this_iter_s\": {\n      \"max\": 44.98227882385254,\n      \"min\": 35.7854540348053,\n      \"avg\": 40.38386642932892,\n      \"last\": 35.7854540348053,\n      \"last-5-avg\": 40.38386642932892,\n      \"last-10-avg\": 40.38386642932892\n    },\n    \"should_checkpoint\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": 1.0,\n      \"last\": true,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_total_s\": {\n      \"max\": 80.76773285865784,\n      \"min\": 44.98227882385254,\n      \"avg\": 62.87500584125519,\n      \"last\": 80.76773285865784,\n      \"last-5-avg\": 62.87500584125519,\n      \"last-10-avg\": 62.87500584125519\n    },\n    \"time_since_restore\": {\n      \"max\": 80.76773285865784,\n      \"min\": 44.98227882385254,\n      \"avg\": 62.87500584125519,\n      \"last\": 80.76773285865784,\n      \"last-5-avg\": 62.87500584125519,\n      \"last-10-avg\": 62.87500584125519\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.00449371337890625,\n      \"min\": 0.00449371337890625,\n      \"avg\": 0.00449371337890625,\n      \"last\": 0.00449371337890625,\n      \"last-5-avg\": 0.00449371337890625,\n      \"last-10-avg\": 0.00449371337890625\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"metric_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe87028a0000000473fed6115c0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe87028a0000000473fed6115c0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740467dbb50000000474041e489c2000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740467dbb50000000474041e489c2000000652e\"\n      }\n    },\n    \"should_checkpoint\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288888652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288888652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740467dbb50000000474054312289000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740467dbb50000000474054312289000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740467dbb50000000474054312289000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740467dbb50000000474054312289000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f72680000000000473f72680000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f72680000000000473f72680000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1656473501.5358772,\n  \"logdir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_fde0797a\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd2024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd3024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": \"trial_fde0797a\",\n  \"custom_dirname\": \"trial_fde0797a\",\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": 1,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"trainable_func_f2we_ZX\",\n  \"trial_id\": \"fdf7393a\",\n  \"config\": {\n    \"trainer.learning_rate\": 0.005,\n    \"trainer.batch_size\": 1024,\n    \"trainer.decay_rate\": 0.95,\n    \"trainer.decay_steps\": 2000,\n    \"combiner.size\": 64,\n    \"combiner.output_size\": 16,\n    \"combiner.num_steps\": 3,\n    \"combiner.relaxation_factor\": 1.2,\n    \"combiner.sparsity\": 0.001,\n    \"combiner.bn_virtual_bs\": 256,\n    \"combiner.bn_momentum\": 0.2\n  },\n  \"local_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt\",\n  \"evaluated_params\": {\n    \"combiner.bn_momentum\": 0.2,\n    \"combiner.bn_virtual_bs\": 256,\n    \"combiner.num_steps\": 3,\n    \"combiner.output_size\": 16,\n    \"combiner.relaxation_factor\": 1.2,\n    \"combiner.size\": 64,\n    \"combiner.sparsity\": 0.001,\n    \"trainer.batch_size\": 1024,\n    \"trainer.decay_rate\": 0.95,\n    \"trainer.decay_steps\": 2000,\n    \"trainer.learning_rate\": 0.005\n  },\n  \"experiment_tag\": \"9_combiner_bn_momentum=0.2000,combiner_bn_virtual_bs=256,combiner_num_steps=3,combiner_output_size=16,combiner_relaxation_factor=1.2000,combiner_size=64,combiner_sparsity=0.0010,trainer_batch_size=1024,trainer_decay_rate=0.9500,trainer_decay_steps=2000,trainer_learning_rate=0.0050\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595a6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 1,\n  \"_last_result\": {\n    \"parameters\": \"{\\\"trainer.learning_rate\\\": 0.005, \\\"trainer.batch_size\\\": 1024, \\\"trainer.decay_rate\\\": 0.95, \\\"trainer.decay_steps\\\": 2000, \\\"combiner.size\\\": 64, \\\"combiner.output_size\\\": 16, \\\"combiner.num_steps\\\": 3, \\\"combiner.relaxation_factor\\\": 1.2, \\\"combiner.sparsity\\\": 0.001, \\\"combiner.bn_virtual_bs\\\": 256, \\\"combiner.bn_momentum\\\": 0.2}\",\n    \"metric_score\": 0.9694716930389404,\n    \"training_stats\": \"{\\\"training\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.24512799084186554, 0.17811575531959534, 0.16127733886241913, 0.10870658606290817], \\\"roc_auc\\\": [0.8396567106246948, 0.9269633293151855, 0.9450514912605286, 0.9776095151901245], \\\"accuracy\\\": [0.904360830783844, 0.9074879884719849, 0.9214111566543579, 0.9505460858345032]}, \\\"combined\\\": {\\\"loss\\\": [0.24579900514800102, 0.1787721262080595, 0.16192077210871503, 0.1093324213870801]}}, \\\"validation\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.25019383430480957, 0.18238691985607147, 0.1745680868625641, 0.1269351840019226], \\\"roc_auc\\\": [0.8347501754760742, 0.9239571690559387, 0.9357465505599976, 0.9694716930389404], \\\"accuracy\\\": [0.9013012647628784, 0.9053815603256226, 0.9144243597984314, 0.9416629672050476]}, \\\"combined\\\": {\\\"loss\\\": [0.2508641980821267, 0.18304208246991038, 0.17521039285929874, 0.1275592963793315]}}, \\\"test\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.2550872564315796, 0.1875327080488205, 0.17313604056835175, 0.12610366940498352], \\\"roc_auc\\\": [0.832984983921051, 0.9218736290931702, 0.938619077205658, 0.9697815775871277], \\\"accuracy\\\": [0.8981415033340454, 0.9013952612876892, 0.9144101738929749, 0.9439144134521484]}, \\\"combined\\\": {\\\"loss\\\": [0.2557588806957938, 0.18818611180176958, 0.17377663764636964, 0.12672493403078988]}}}\",\n    \"eval_stats\": \"{}\",\n    \"trial_id\": \"fdf7393a\",\n    \"trial_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_fdf7393a/\",\n    \"time_this_iter_s\": 15.207165002822876,\n    \"should_checkpoint\": true,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 4,\n    \"experiment_id\": \"9713fff52bac4d059853ca2760d80201\",\n    \"date\": \"2022-06-28_23-33-15\",\n    \"timestamp\": 1656473595,\n    \"time_total_s\": 85.88274693489075,\n    \"pid\": 44876,\n    \"hostname\": \"C02FR8FUMD6R.grubhub.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"trainer.learning_rate\": 0.005,\n      \"trainer.batch_size\": 1024,\n      \"trainer.decay_rate\": 0.95,\n      \"trainer.decay_steps\": 2000,\n      \"combiner.size\": 64,\n      \"combiner.output_size\": 16,\n      \"combiner.num_steps\": 3,\n      \"combiner.relaxation_factor\": 1.2,\n      \"combiner.sparsity\": 0.001,\n      \"combiner.bn_virtual_bs\": 256,\n      \"combiner.bn_momentum\": 0.2\n    },\n    \"time_since_restore\": 85.88274693489075,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 4,\n    \"warmup_time\": 0.004148006439208984,\n    \"experiment_tag\": \"9_combiner_bn_momentum=0.2000,combiner_bn_virtual_bs=256,combiner_num_steps=3,combiner_output_size=16,combiner_relaxation_factor=1.2000,combiner_size=64,combiner_sparsity=0.0010,trainer_batch_size=1024,trainer_decay_rate=0.9500,trainer_decay_steps=2000,trainer_learning_rate=0.0050\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1656473595.46751,\n  \"metric_analysis\": {\n    \"metric_score\": {\n      \"max\": 0.9694716930389404,\n      \"min\": 0.8347501754760742,\n      \"avg\": 0.9159813970327377,\n      \"last\": 0.9694716930389404,\n      \"last-5-avg\": 0.9159813970327377,\n      \"last-10-avg\": 0.9159813970327377\n    },\n    \"time_this_iter_s\": {\n      \"max\": 24.620258808135986,\n      \"min\": 15.207165002822876,\n      \"avg\": 21.470686733722687,\n      \"last\": 15.207165002822876,\n      \"last-5-avg\": 21.470686733722687,\n      \"last-10-avg\": 21.470686733722687\n    },\n    \"should_checkpoint\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": 1.0,\n      \"last\": true,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.25,\n      \"last\": true,\n      \"last-5-avg\": 0.25,\n      \"last-10-avg\": 0.25\n    },\n    \"training_iteration\": {\n      \"max\": 4,\n      \"min\": 1,\n      \"avg\": 2.5,\n      \"last\": 4,\n      \"last-5-avg\": 2.5,\n      \"last-10-avg\": 2.5\n    },\n    \"time_total_s\": {\n      \"max\": 85.88274693489075,\n      \"min\": 24.620258808135986,\n      \"avg\": 57.29916310310364,\n      \"last\": 85.88274693489075,\n      \"last-5-avg\": 57.29916310310364,\n      \"last-10-avg\": 57.29916310310364\n    },\n    \"time_since_restore\": {\n      \"max\": 85.88274693489075,\n      \"min\": 24.620258808135986,\n      \"avg\": 57.29916310310364,\n      \"last\": 85.88274693489075,\n      \"last-5-avg\": 57.29916310310364,\n      \"last-10-avg\": 57.29916310310364\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 4,\n      \"min\": 1,\n      \"avg\": 2.5,\n      \"last\": 4,\n      \"last-5-avg\": 2.5,\n      \"last-10-avg\": 2.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.004148006439208984,\n      \"min\": 0.004148006439208984,\n      \"avg\": 0.004148006439208984,\n      \"last\": 0.004148006439208984,\n      \"last-5-avg\": 0.004148006439208984,\n      \"last-10-avg\": 0.004148006439208984\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"metric_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473feab64600000000473fed910ea0000000473fedf1a2c0000000473fef05e980000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473feab64600000000473fed910ea0000000473fedf1a2c0000000473fef05e980000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740389ec94800000047403765d69c000000474036a8530c00000047402e6a1188000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740389ec94800000047403765d69c000000474036a8530c00000047402e6a1188000000652e\"\n      }\n    },\n    \"should_checkpoint\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942888888888652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942888888888652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942889898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b034b04652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b04652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740389ec948000000474048024ff2000000474051ab3cbc000000474055787eed000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740389ec948000000474048024ff2000000474051ab3cbc000000474055787eed000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740389ec948000000474048024ff2000000474051ab3cbc000000474055787eed000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740389ec948000000474048024ff2000000474051ab3cbc000000474055787eed000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b034b04652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b04652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f70fd8000000000473f70fd8000000000473f70fd8000000000473f70fd8000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f70fd8000000000473f70fd8000000000473f70fd8000000000473f70fd8000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1656473501.685173,\n  \"logdir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_fdf7393a\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd2024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd3024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": \"trial_fdf7393a\",\n  \"custom_dirname\": \"trial_fdf7393a\",\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": 1,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"trainable_func_f2we_ZX\",\n  \"trial_id\": \"fdda4e74\",\n  \"config\": {\n    \"trainer.learning_rate\": 0.005,\n    \"trainer.batch_size\": 1024,\n    \"trainer.decay_rate\": 0.95,\n    \"trainer.decay_steps\": 10000,\n    \"combiner.size\": 32,\n    \"combiner.output_size\": 128,\n    \"combiner.num_steps\": 9,\n    \"combiner.relaxation_factor\": 1.0,\n    \"combiner.sparsity\": 0.0,\n    \"combiner.bn_virtual_bs\": 256,\n    \"combiner.bn_momentum\": 0.2\n  },\n  \"local_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt\",\n  \"evaluated_params\": {\n    \"combiner.bn_momentum\": 0.2,\n    \"combiner.bn_virtual_bs\": 256,\n    \"combiner.num_steps\": 9,\n    \"combiner.output_size\": 128,\n    \"combiner.relaxation_factor\": 1.0,\n    \"combiner.size\": 32,\n    \"combiner.sparsity\": 0.0,\n    \"trainer.batch_size\": 1024,\n    \"trainer.decay_rate\": 0.95,\n    \"trainer.decay_steps\": 10000,\n    \"trainer.learning_rate\": 0.005\n  },\n  \"experiment_tag\": \"2_combiner_bn_momentum=0.2000,combiner_bn_virtual_bs=256,combiner_num_steps=9,combiner_output_size=128,combiner_relaxation_factor=1.0000,combiner_size=32,combiner_sparsity=0.0000,trainer_batch_size=1024,trainer_decay_rate=0.9500,trainer_decay_steps=10000,trainer_learning_rate=0.0050\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595a6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 1,\n  \"_last_result\": {\n    \"parameters\": \"{\\\"trainer.learning_rate\\\": 0.005, \\\"trainer.batch_size\\\": 1024, \\\"trainer.decay_rate\\\": 0.95, \\\"trainer.decay_steps\\\": 10000, \\\"combiner.size\\\": 32, \\\"combiner.output_size\\\": 128, \\\"combiner.num_steps\\\": 9, \\\"combiner.relaxation_factor\\\": 1.0, \\\"combiner.sparsity\\\": 0.0, \\\"combiner.bn_virtual_bs\\\": 256, \\\"combiner.bn_momentum\\\": 0.2}\",\n    \"metric_score\": 0.78572016954422,\n    \"training_stats\": \"{\\\"training\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.7784332036972046], \\\"roc_auc\\\": [0.7803532481193542], \\\"accuracy\\\": [0.6123359799385071]}, \\\"combined\\\": {\\\"loss\\\": [0.7784332036972046]}}, \\\"validation\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.7673763036727905], \\\"roc_auc\\\": [0.78572016954422], \\\"accuracy\\\": [0.6205337643623352]}, \\\"combined\\\": {\\\"loss\\\": [0.7673763036727905]}}, \\\"test\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.7604444622993469], \\\"roc_auc\\\": [0.773817241191864], \\\"accuracy\\\": [0.6108200550079346]}, \\\"combined\\\": {\\\"loss\\\": [0.7604444622993469]}}}\",\n    \"eval_stats\": \"{}\",\n    \"trial_id\": \"fdda4e74\",\n    \"trial_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_fdda4e74/\",\n    \"time_this_iter_s\": 88.4615957736969,\n    \"should_checkpoint\": true,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"experiment_id\": \"8f7d14ca3f094e44beec84699321218e\",\n    \"date\": \"2022-06-28_23-33-18\",\n    \"timestamp\": 1656473598,\n    \"time_total_s\": 88.4615957736969,\n    \"pid\": 44860,\n    \"hostname\": \"C02FR8FUMD6R.grubhub.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"trainer.learning_rate\": 0.005,\n      \"trainer.batch_size\": 1024,\n      \"trainer.decay_rate\": 0.95,\n      \"trainer.decay_steps\": 10000,\n      \"combiner.size\": 32,\n      \"combiner.output_size\": 128,\n      \"combiner.num_steps\": 9,\n      \"combiner.relaxation_factor\": 1.0,\n      \"combiner.sparsity\": 0.0,\n      \"combiner.bn_virtual_bs\": 256,\n      \"combiner.bn_momentum\": 0.2\n    },\n    \"time_since_restore\": 88.4615957736969,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.0052220821380615234,\n    \"experiment_tag\": \"2_combiner_bn_momentum=0.2000,combiner_bn_virtual_bs=256,combiner_num_steps=9,combiner_output_size=128,combiner_relaxation_factor=1.0000,combiner_size=32,combiner_sparsity=0.0000,trainer_batch_size=1024,trainer_decay_rate=0.9500,trainer_decay_steps=10000,trainer_learning_rate=0.0050\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1656473598.0386019,\n  \"metric_analysis\": {\n    \"metric_score\": {\n      \"max\": 0.78572016954422,\n      \"min\": 0.78572016954422,\n      \"avg\": 0.78572016954422,\n      \"last\": 0.78572016954422,\n      \"last-5-avg\": 0.78572016954422,\n      \"last-10-avg\": 0.78572016954422\n    },\n    \"time_this_iter_s\": {\n      \"max\": 88.4615957736969,\n      \"min\": 88.4615957736969,\n      \"avg\": 88.4615957736969,\n      \"last\": 88.4615957736969,\n      \"last-5-avg\": 88.4615957736969,\n      \"last-10-avg\": 88.4615957736969\n    },\n    \"should_checkpoint\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 88.4615957736969,\n      \"min\": 88.4615957736969,\n      \"avg\": 88.4615957736969,\n      \"last\": 88.4615957736969,\n      \"last-5-avg\": 88.4615957736969,\n      \"last-10-avg\": 88.4615957736969\n    },\n    \"time_since_restore\": {\n      \"max\": 88.4615957736969,\n      \"min\": 88.4615957736969,\n      \"avg\": 88.4615957736969,\n      \"last\": 88.4615957736969,\n      \"last-5-avg\": 88.4615957736969,\n      \"last-10-avg\": 88.4615957736969\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.0052220821380615234,\n      \"min\": 0.0052220821380615234,\n      \"avg\": 0.0052220821380615234,\n      \"last\": 0.0052220821380615234,\n      \"last-5-avg\": 0.0052220821380615234,\n      \"last-10-avg\": 0.0052220821380615234\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"metric_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe9249ea0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe9249ea0000000612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740561d8ac9000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740561d8ac9000000612e\"\n      }\n    },\n    \"should_checkpoint\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740561d8ac9000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740561d8ac9000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740561d8ac9000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740561d8ac9000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f7563c000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f7563c000000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1656473501.482993,\n  \"logdir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_fdda4e74\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd2024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd3024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": \"trial_fdda4e74\",\n  \"custom_dirname\": \"trial_fdda4e74\",\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": 1,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"trainable_func_f2we_ZX\",\n  \"trial_id\": \"fde9ac98\",\n  \"config\": {\n    \"trainer.learning_rate\": 0.005,\n    \"trainer.batch_size\": 512,\n    \"trainer.decay_rate\": 0.9,\n    \"trainer.decay_steps\": 8000,\n    \"combiner.size\": 16,\n    \"combiner.output_size\": 16,\n    \"combiner.num_steps\": 3,\n    \"combiner.relaxation_factor\": 1.2,\n    \"combiner.sparsity\": 0.01,\n    \"combiner.bn_virtual_bs\": 256,\n    \"combiner.bn_momentum\": 0.4\n  },\n  \"local_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt\",\n  \"evaluated_params\": {\n    \"combiner.bn_momentum\": 0.4,\n    \"combiner.bn_virtual_bs\": 256,\n    \"combiner.num_steps\": 3,\n    \"combiner.output_size\": 16,\n    \"combiner.relaxation_factor\": 1.2,\n    \"combiner.size\": 16,\n    \"combiner.sparsity\": 0.01,\n    \"trainer.batch_size\": 512,\n    \"trainer.decay_rate\": 0.9,\n    \"trainer.decay_steps\": 8000,\n    \"trainer.learning_rate\": 0.005\n  },\n  \"experiment_tag\": \"6_combiner_bn_momentum=0.4000,combiner_bn_virtual_bs=256,combiner_num_steps=3,combiner_output_size=16,combiner_relaxation_factor=1.2000,combiner_size=16,combiner_sparsity=0.0100,trainer_batch_size=512,trainer_decay_rate=0.9000,trainer_decay_steps=8000,trainer_learning_rate=0.0050\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595a6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 1,\n  \"_last_result\": {\n    \"parameters\": \"{\\\"trainer.learning_rate\\\": 0.005, \\\"trainer.batch_size\\\": 512, \\\"trainer.decay_rate\\\": 0.9, \\\"trainer.decay_steps\\\": 8000, \\\"combiner.size\\\": 16, \\\"combiner.output_size\\\": 16, \\\"combiner.num_steps\\\": 3, \\\"combiner.relaxation_factor\\\": 1.2, \\\"combiner.sparsity\\\": 0.01, \\\"combiner.bn_virtual_bs\\\": 256, \\\"combiner.bn_momentum\\\": 0.4}\",\n    \"metric_score\": 0.9808773994445801,\n    \"training_stats\": \"{\\\"training\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.23481234908103943, 0.16789934039115906, 0.12352447956800461, 0.08205988258123398], \\\"roc_auc\\\": [0.8582466244697571, 0.9391092658042908, 0.9716773629188538, 0.9867356419563293], \\\"accuracy\\\": [0.9040465354919434, 0.9126895666122437, 0.9458159804344177, 0.9652235507965088]}, \\\"combined\\\": {\\\"loss\\\": [0.24196831975132227, 0.17340475926175714, 0.12819113535806537, 0.08630837313830853]}}, \\\"validation\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.23523327708244324, 0.17745670676231384, 0.13859692215919495, 0.09631417691707611], \\\"roc_auc\\\": [0.8621048927307129, 0.9327791333198547, 0.962490439414978, 0.9808773994445801], \\\"accuracy\\\": [0.9015218615531921, 0.9075871109962463, 0.9367004632949829, 0.9580944180488586]}, \\\"combined\\\": {\\\"loss\\\": [0.2423906810581684, 0.18283199984580278, 0.1432144525460899, 0.10053108679130673]}}, \\\"test\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.24164335429668427, 0.1789311170578003, 0.1416245996952057, 0.10085224360227585], \\\"roc_auc\\\": [0.8597664833068848, 0.9339866042137146, 0.9626750946044922, 0.9782354235649109], \\\"accuracy\\\": [0.8983621001243591, 0.9078475832939148, 0.9363591074943542, 0.9568741917610168]}, \\\"combined\\\": {\\\"loss\\\": [0.24880694830790162, 0.1840855125337839, 0.14615480555221438, 0.10501336632296443]}}}\",\n    \"eval_stats\": \"{}\",\n    \"trial_id\": \"fde9ac98\",\n    \"trial_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_fde9ac98/\",\n    \"time_this_iter_s\": 14.82785701751709,\n    \"should_checkpoint\": true,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 4,\n    \"experiment_id\": \"5ed64276b67348ee8d94df5a81ad329f\",\n    \"date\": \"2022-06-28_23-33-02\",\n    \"timestamp\": 1656473582,\n    \"time_total_s\": 72.62150716781616,\n    \"pid\": 44867,\n    \"hostname\": \"C02FR8FUMD6R.grubhub.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"trainer.learning_rate\": 0.005,\n      \"trainer.batch_size\": 512,\n      \"trainer.decay_rate\": 0.9,\n      \"trainer.decay_steps\": 8000,\n      \"combiner.size\": 16,\n      \"combiner.output_size\": 16,\n      \"combiner.num_steps\": 3,\n      \"combiner.relaxation_factor\": 1.2,\n      \"combiner.sparsity\": 0.01,\n      \"combiner.bn_virtual_bs\": 256,\n      \"combiner.bn_momentum\": 0.4\n    },\n    \"time_since_restore\": 72.62150716781616,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 4,\n    \"warmup_time\": 0.004971027374267578,\n    \"experiment_tag\": \"6_combiner_bn_momentum=0.4000,combiner_bn_virtual_bs=256,combiner_num_steps=3,combiner_output_size=16,combiner_relaxation_factor=1.2000,combiner_size=16,combiner_sparsity=0.0100,trainer_batch_size=512,trainer_decay_rate=0.9000,trainer_decay_steps=8000,trainer_learning_rate=0.0050\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1656473582.277985,\n  \"metric_analysis\": {\n    \"metric_score\": {\n      \"max\": 0.9808773994445801,\n      \"min\": 0.8621048927307129,\n      \"avg\": 0.9345629662275314,\n      \"last\": 0.9808773994445801,\n      \"last-5-avg\": 0.9345629662275314,\n      \"last-10-avg\": 0.9345629662275314\n    },\n    \"time_this_iter_s\": {\n      \"max\": 19.621782064437866,\n      \"min\": 14.82785701751709,\n      \"avg\": 18.15537679195404,\n      \"last\": 14.82785701751709,\n      \"last-5-avg\": 18.15537679195404,\n      \"last-10-avg\": 18.15537679195404\n    },\n    \"should_checkpoint\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": 1.0,\n      \"last\": true,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.25,\n      \"last\": true,\n      \"last-5-avg\": 0.25,\n      \"last-10-avg\": 0.25\n    },\n    \"training_iteration\": {\n      \"max\": 4,\n      \"min\": 1,\n      \"avg\": 2.5,\n      \"last\": 4,\n      \"last-5-avg\": 2.5,\n      \"last-10-avg\": 2.5\n    },\n    \"time_total_s\": {\n      \"max\": 72.62150716781616,\n      \"min\": 19.621782064437866,\n      \"avg\": 47.07698863744736,\n      \"last\": 72.62150716781616,\n      \"last-5-avg\": 47.07698863744736,\n      \"last-10-avg\": 47.07698863744736\n    },\n    \"time_since_restore\": {\n      \"max\": 72.62150716781616,\n      \"min\": 19.621782064437866,\n      \"avg\": 47.07698863744736,\n      \"last\": 72.62150716781616,\n      \"last-5-avg\": 47.07698863744736,\n      \"last-10-avg\": 47.07698863744736\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 4,\n      \"min\": 1,\n      \"avg\": 2.5,\n      \"last\": 4,\n      \"last-5-avg\": 2.5,\n      \"last-10-avg\": 2.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.004971027374267578,\n      \"min\": 0.004971027374267578,\n      \"avg\": 0.004971027374267578,\n      \"last\": 0.004971027374267578,\n      \"last-5-avg\": 0.004971027374267578,\n      \"last-10-avg\": 0.004971027374267578\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"metric_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473feb965d00000000473fedd953a0000000473feeccb8c0000000473fef635900000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473feb965d00000000473fedd953a0000000473feeccb8c0000000473fef635900000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740339f2d1c000000474032a6342400000047403385cb6800000047402da7dce0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740339f2d1c000000474032a6342400000047403385cb6800000047402da7dce0000000652e\"\n      }\n    },\n    \"should_checkpoint\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942888888888652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942888888888652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942889898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b034b04652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b04652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740339f2d1c00000047404322b0a000000047404ce5965400000047405227c6c6000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740339f2d1c00000047404322b0a000000047404ce5965400000047405227c6c6000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740339f2d1c00000047404322b0a000000047404ce5965400000047405227c6c6000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740339f2d1c00000047404322b0a000000047404ce5965400000047405227c6c6000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b034b04652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b04652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f745c8000000000473f745c8000000000473f745c8000000000473f745c8000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f745c8000000000473f745c8000000000473f745c8000000000473f745c8000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1656473501.5941381,\n  \"logdir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_fde9ac98\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd2024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd3024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": \"trial_fde9ac98\",\n  \"custom_dirname\": \"trial_fde9ac98\",\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": 1,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_insufficient_resources_manager": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "8005958b000000000000008c277261792e74756e652e696e73756666696369656e745f7265736f75726365735f6d616e61676572948c1c496e73756666696369656e745265736f75726365734d616e616765729493942981947d94288c185f6e6f5f72756e6e696e675f747269616c735f73696e6365944affffffff8c0f5f6c6173745f747269616c5f6e756d944affffffff75622e"
    },
    "_max_pending_trials": 1,
    "_metric": "metric_score",
    "_total_time": 886.7421705722809,
    "_iteration": 83,
    "_has_errored": false,
    "_fail_fast": false,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "800595de000000000000008c107261792e74756e652e73746f70706572948c0f436f6d62696e656453746f707065729493942981947d948c095f73746f7070657273948c196c75647769672e68797065726f70742e657865637574696f6e948c0f43616c6c6261636b53746f707065729493942981947d948c0963616c6c6261636b73945d94736268008c0e54696d656f757453746f707065729493942981947d94288c105f74696d656f75745f7365636f6e6473944b788c075f6275646765749447bff34647800000008c0b5f6c6173745f636865636b944741d8aef204c3c1167562869473622e"
    },
    "_resumed": false,
    "_start_time": 1656473497.694397,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2022-06-28_23-31-37",
    "checkpoint_file": "/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/experiment_state-2022-06-28_23-31-37.json",
    "_checkpoint_period": "auto",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1656473497.694397,
    "timestamp": 1656473619.0845299
  }
}