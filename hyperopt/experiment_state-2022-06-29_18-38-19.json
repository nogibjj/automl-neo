{
  "checkpoints": [
    "{\n  \"stub\": false,\n  \"trainable_name\": \"trainable_func_f2we_ZX\",\n  \"trial_id\": \"bdc058b6\",\n  \"config\": {\n    \"trainer.learning_rate\": 0.005,\n    \"trainer.batch_size\": 1024,\n    \"trainer.decay_rate\": 0.95,\n    \"trainer.decay_steps\": 10000,\n    \"combiner.size\": 32,\n    \"combiner.output_size\": 128,\n    \"combiner.num_steps\": 9,\n    \"combiner.relaxation_factor\": 1.0,\n    \"combiner.sparsity\": 0.0,\n    \"combiner.bn_virtual_bs\": 256,\n    \"combiner.bn_momentum\": 0.2\n  },\n  \"local_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt\",\n  \"evaluated_params\": {\n    \"combiner.bn_momentum\": 0.2,\n    \"combiner.bn_virtual_bs\": 256,\n    \"combiner.num_steps\": 9,\n    \"combiner.output_size\": 128,\n    \"combiner.relaxation_factor\": 1.0,\n    \"combiner.size\": 32,\n    \"combiner.sparsity\": 0.0,\n    \"trainer.batch_size\": 1024,\n    \"trainer.decay_rate\": 0.95,\n    \"trainer.decay_steps\": 10000,\n    \"trainer.learning_rate\": 0.005\n  },\n  \"experiment_tag\": \"2_combiner_bn_momentum=0.2000,combiner_bn_virtual_bs=256,combiner_num_steps=9,combiner_output_size=128,combiner_relaxation_factor=1.0000,combiner_size=32,combiner_sparsity=0.0000,trainer_batch_size=1024,trainer_decay_rate=0.9500,trainer_decay_steps=10000,trainer_learning_rate=0.0050\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595a6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 1,\n  \"_last_result\": {\n    \"parameters\": \"{\\\"trainer.learning_rate\\\": 0.005, \\\"trainer.batch_size\\\": 1024, \\\"trainer.decay_rate\\\": 0.95, \\\"trainer.decay_steps\\\": 10000, \\\"combiner.size\\\": 32, \\\"combiner.output_size\\\": 128, \\\"combiner.num_steps\\\": 9, \\\"combiner.relaxation_factor\\\": 1.0, \\\"combiner.sparsity\\\": 0.0, \\\"combiner.bn_virtual_bs\\\": 256, \\\"combiner.bn_momentum\\\": 0.2}\",\n    \"metric_score\": 0.78572016954422,\n    \"training_stats\": \"{\\\"training\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.7784332036972046], \\\"roc_auc\\\": [0.7803532481193542], \\\"accuracy\\\": [0.6123359799385071]}, \\\"combined\\\": {\\\"loss\\\": [0.7784332036972046]}}, \\\"validation\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.7673763036727905], \\\"roc_auc\\\": [0.78572016954422], \\\"accuracy\\\": [0.6205337643623352]}, \\\"combined\\\": {\\\"loss\\\": [0.7673763036727905]}}, \\\"test\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.7604444622993469], \\\"roc_auc\\\": [0.773817241191864], \\\"accuracy\\\": [0.6108200550079346]}, \\\"combined\\\": {\\\"loss\\\": [0.7604444622993469]}}}\",\n    \"eval_stats\": \"{}\",\n    \"trial_id\": \"bdc058b6\",\n    \"trial_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_bdc058b6/\",\n    \"time_this_iter_s\": 106.9776668548584,\n    \"should_checkpoint\": true,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"experiment_id\": \"d5ecfcb77c334e3caa3e0c439d332cc2\",\n    \"date\": \"2022-06-29_18-29-59\",\n    \"timestamp\": 1656541799,\n    \"time_total_s\": 106.9776668548584,\n    \"pid\": 72865,\n    \"hostname\": \"C02FR8FUMD6R.grubhub.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"trainer.learning_rate\": 0.005,\n      \"trainer.batch_size\": 1024,\n      \"trainer.decay_rate\": 0.95,\n      \"trainer.decay_steps\": 10000,\n      \"combiner.size\": 32,\n      \"combiner.output_size\": 128,\n      \"combiner.num_steps\": 9,\n      \"combiner.relaxation_factor\": 1.0,\n      \"combiner.sparsity\": 0.0,\n      \"combiner.bn_virtual_bs\": 256,\n      \"combiner.bn_momentum\": 0.2\n    },\n    \"time_since_restore\": 106.9776668548584,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.0036742687225341797,\n    \"experiment_tag\": \"2_combiner_bn_momentum=0.2000,combiner_bn_virtual_bs=256,combiner_num_steps=9,combiner_output_size=128,combiner_relaxation_factor=1.0000,combiner_size=32,combiner_sparsity=0.0000,trainer_batch_size=1024,trainer_decay_rate=0.9500,trainer_decay_steps=10000,trainer_learning_rate=0.0050\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1656541799.043839,\n  \"metric_analysis\": {\n    \"metric_score\": {\n      \"max\": 0.78572016954422,\n      \"min\": 0.78572016954422,\n      \"avg\": 0.78572016954422,\n      \"last\": 0.78572016954422,\n      \"last-5-avg\": 0.78572016954422,\n      \"last-10-avg\": 0.78572016954422\n    },\n    \"time_this_iter_s\": {\n      \"max\": 106.9776668548584,\n      \"min\": 106.9776668548584,\n      \"avg\": 106.9776668548584,\n      \"last\": 106.9776668548584,\n      \"last-5-avg\": 106.9776668548584,\n      \"last-10-avg\": 106.9776668548584\n    },\n    \"should_checkpoint\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 106.9776668548584,\n      \"min\": 106.9776668548584,\n      \"avg\": 106.9776668548584,\n      \"last\": 106.9776668548584,\n      \"last-5-avg\": 106.9776668548584,\n      \"last-10-avg\": 106.9776668548584\n    },\n    \"time_since_restore\": {\n      \"max\": 106.9776668548584,\n      \"min\": 106.9776668548584,\n      \"avg\": 106.9776668548584,\n      \"last\": 106.9776668548584,\n      \"last-5-avg\": 106.9776668548584,\n      \"last-10-avg\": 106.9776668548584\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.0036742687225341797,\n      \"min\": 0.0036742687225341797,\n      \"avg\": 0.0036742687225341797,\n      \"last\": 0.0036742687225341797,\n      \"last-5-avg\": 0.0036742687225341797,\n      \"last-10-avg\": 0.0036742687225341797\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"metric_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473fe9249ea0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473fe9249ea0000000612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405abe9218000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405abe9218000000612e\"\n      }\n    },\n    \"should_checkpoint\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405abe9218000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405abe9218000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405abe9218000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405abe9218000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f6e198000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f6e198000000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1656541683.916445,\n  \"logdir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_bdc058b6\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd2024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd3024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": \"trial_bdc058b6\",\n  \"custom_dirname\": \"trial_bdc058b6\",\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": 1,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"trainable_func_f2we_ZX\",\n  \"trial_id\": \"bdc2b746\",\n  \"config\": {\n    \"trainer.learning_rate\": 0.005,\n    \"trainer.batch_size\": 512,\n    \"trainer.decay_rate\": 0.8,\n    \"trainer.decay_steps\": 500,\n    \"combiner.size\": 8,\n    \"combiner.output_size\": 8,\n    \"combiner.num_steps\": 3,\n    \"combiner.relaxation_factor\": 1.0,\n    \"combiner.sparsity\": 1e-06,\n    \"combiner.bn_virtual_bs\": 1024,\n    \"combiner.bn_momentum\": 0.02\n  },\n  \"local_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt\",\n  \"evaluated_params\": {\n    \"combiner.bn_momentum\": 0.02,\n    \"combiner.bn_virtual_bs\": 1024,\n    \"combiner.num_steps\": 3,\n    \"combiner.output_size\": 8,\n    \"combiner.relaxation_factor\": 1.0,\n    \"combiner.size\": 8,\n    \"combiner.sparsity\": 1e-06,\n    \"trainer.batch_size\": 512,\n    \"trainer.decay_rate\": 0.8,\n    \"trainer.decay_steps\": 500,\n    \"trainer.learning_rate\": 0.005\n  },\n  \"experiment_tag\": \"3_combiner_bn_momentum=0.0200,combiner_bn_virtual_bs=1024,combiner_num_steps=3,combiner_output_size=8,combiner_relaxation_factor=1.0000,combiner_size=8,combiner_sparsity=0.0000,trainer_batch_size=512,trainer_decay_rate=0.8000,trainer_decay_steps=500,trainer_learning_rate=0.0050\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595a6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 1,\n  \"_last_result\": {\n    \"parameters\": \"{\\\"trainer.learning_rate\\\": 0.005, \\\"trainer.batch_size\\\": 512, \\\"trainer.decay_rate\\\": 0.8, \\\"trainer.decay_steps\\\": 500, \\\"combiner.size\\\": 8, \\\"combiner.output_size\\\": 8, \\\"combiner.num_steps\\\": 3, \\\"combiner.relaxation_factor\\\": 1.0, \\\"combiner.sparsity\\\": 1e-06, \\\"combiner.bn_virtual_bs\\\": 1024, \\\"combiner.bn_momentum\\\": 0.02}\",\n    \"metric_score\": 0.9806248545646667,\n    \"training_stats\": \"{\\\"training\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.41980960965156555, 0.1886724829673767, 0.12610362470149994, 0.08308761566877365, 0.07712692767381668], \\\"roc_auc\\\": [0.7787164449691772, 0.9190508127212524, 0.9705900549888611, 0.9869155287742615, 0.9838906526565552], \\\"accuracy\\\": [0.9040622115135193, 0.9057593941688538, 0.9435373544692993, 0.9655849933624268, 0.9720279574394226]}, \\\"combined\\\": {\\\"loss\\\": [0.41981161483704454, 0.18867404351749428, 0.12610492644705573, 0.08308878814023046, 0.0771280116558728]}}, \\\"validation\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.42158612608909607, 0.1907925009727478, 0.14003293216228485, 0.0986025258898735, 0.09832314401865005], \\\"roc_auc\\\": [0.7813661098480225, 0.9182260036468506, 0.9620145559310913, 0.9806248545646667, 0.9752957224845886], \\\"accuracy\\\": [0.9016321301460266, 0.9029554724693298, 0.933722972869873, 0.9564402103424072, 0.9665858149528503]}, \\\"combined\\\": {\\\"loss\\\": [0.42158813078935964, 0.19079402596685213, 0.14003421729489673, 0.09860368910426587, 0.0983242205403485]}}, \\\"test\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.4244043231010437, 0.19957484304904938, 0.13952387869358063, 0.09919699281454086, 0.09547703713178635], \\\"roc_auc\\\": [0.7765635251998901, 0.9156337380409241, 0.9648204445838928, 0.9815257787704468, 0.9767876267433167], \\\"accuracy\\\": [0.8983621001243591, 0.8987481594085693, 0.934814989566803, 0.9573705196380615, 0.9640434384346008]}, \\\"combined\\\": {\\\"loss\\\": [0.42440632814509627, 0.19957630798285209, 0.13952513389756405, 0.09919813912517839, 0.0954780998268916]}}}\",\n    \"eval_stats\": \"{}\",\n    \"trial_id\": \"bdc2b746\",\n    \"trial_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_bdc2b746/\",\n    \"time_this_iter_s\": 18.174872875213623,\n    \"should_checkpoint\": true,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 5,\n    \"experiment_id\": \"51da8e49313a4b588f88cb4c246dbed6\",\n    \"date\": \"2022-06-29_18-29-38\",\n    \"timestamp\": 1656541778,\n    \"time_total_s\": 86.56120300292969,\n    \"pid\": 72866,\n    \"hostname\": \"C02FR8FUMD6R.grubhub.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"trainer.learning_rate\": 0.005,\n      \"trainer.batch_size\": 512,\n      \"trainer.decay_rate\": 0.8,\n      \"trainer.decay_steps\": 500,\n      \"combiner.size\": 8,\n      \"combiner.output_size\": 8,\n      \"combiner.num_steps\": 3,\n      \"combiner.relaxation_factor\": 1.0,\n      \"combiner.sparsity\": 1e-06,\n      \"combiner.bn_virtual_bs\": 1024,\n      \"combiner.bn_momentum\": 0.02\n    },\n    \"time_since_restore\": 86.56120300292969,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 5,\n    \"warmup_time\": 0.0042459964752197266,\n    \"experiment_tag\": \"3_combiner_bn_momentum=0.0200,combiner_bn_virtual_bs=1024,combiner_num_steps=3,combiner_output_size=8,combiner_relaxation_factor=1.0000,combiner_size=8,combiner_sparsity=0.0000,trainer_batch_size=512,trainer_decay_rate=0.8000,trainer_decay_steps=500,trainer_learning_rate=0.0050\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1656541778.638549,\n  \"metric_analysis\": {\n    \"metric_score\": {\n      \"max\": 0.9806248545646667,\n      \"min\": 0.7813661098480225,\n      \"avg\": 0.9245712757110596,\n      \"last\": 0.9806248545646667,\n      \"last-5-avg\": 0.9245712757110596,\n      \"last-10-avg\": 0.9245712757110596\n    },\n    \"time_this_iter_s\": {\n      \"max\": 20.72782588005066,\n      \"min\": 13.983663320541382,\n      \"avg\": 17.312240600585938,\n      \"last\": 18.174872875213623,\n      \"last-5-avg\": 17.312240600585938,\n      \"last-10-avg\": 17.312240600585938\n    },\n    \"should_checkpoint\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": 1.0,\n      \"last\": true,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.2,\n      \"last\": true,\n      \"last-5-avg\": 0.2,\n      \"last-10-avg\": 0.2\n    },\n    \"training_iteration\": {\n      \"max\": 5,\n      \"min\": 1,\n      \"avg\": 3.0,\n      \"last\": 5,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    },\n    \"time_total_s\": {\n      \"max\": 86.56120300292969,\n      \"min\": 14.788613080978394,\n      \"avg\": 51.56273078918457,\n      \"last\": 86.56120300292969,\n      \"last-5-avg\": 51.56273078918457,\n      \"last-10-avg\": 51.56273078918457\n    },\n    \"time_since_restore\": {\n      \"max\": 86.56120300292969,\n      \"min\": 14.788613080978394,\n      \"avg\": 51.56273078918457,\n      \"last\": 86.56120300292969,\n      \"last-5-avg\": 51.56273078918457,\n      \"last-10-avg\": 51.56273078918457\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 5,\n      \"min\": 1,\n      \"avg\": 3.0,\n      \"last\": 5,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    },\n    \"warmup_time\": {\n      \"max\": 0.0042459964752197266,\n      \"min\": 0.0042459964752197266,\n      \"avg\": 0.0042459964752197266,\n      \"last\": 0.0042459964752197266,\n      \"last-5-avg\": 0.0042459964752197266,\n      \"last-10-avg\": 0.0042459964752197266\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"metric_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe900f380000000473fed621b80000000473feec8d2c0000000473fef614760000000473fef614760000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe900f380000000473fed621b80000000473feec8d2c0000000473fef614760000000473fef614760000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847402d93c518000000474032e2dfd4000000474034ba52cc00000047402bf7a2b80000004740322cc478000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847402d93c518000000474032e2dfd4000000474034ba52cc00000047402bf7a2b80000004740322cc478000000652e\"\n      }\n    },\n    \"should_checkpoint\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288888888888652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288888888888652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288989898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b034b044b05652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b05652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847402d93c518000000474040d6613000000047404b338a9600000047405118b9a2000000474055a3eac0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847402d93c518000000474040d6613000000047404b338a9600000047405118b9a2000000474055a3eac0000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847402d93c518000000474040d6613000000047404b338a9600000047405118b9a2000000474055a3eac0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847402d93c518000000474040d6613000000047404b338a9600000047405118b9a2000000474055a3eac0000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b034b044b05652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b05652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f71644000000000473f71644000000000473f71644000000000473f71644000000000473f71644000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f71644000000000473f71644000000000473f71644000000000473f71644000000000473f71644000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1656541683.938926,\n  \"logdir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_bdc2b746\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd2024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd3024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": \"trial_bdc2b746\",\n  \"custom_dirname\": \"trial_bdc2b746\",\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": 1,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"trainable_func_f2we_ZX\",\n  \"trial_id\": \"bb6a6854\",\n  \"config\": {\n    \"trainer.learning_rate\": 0.025,\n    \"trainer.batch_size\": 2048,\n    \"trainer.decay_rate\": 0.95,\n    \"trainer.decay_steps\": 500,\n    \"combiner.size\": 32,\n    \"combiner.output_size\": 8,\n    \"combiner.num_steps\": 4,\n    \"combiner.relaxation_factor\": 1.0,\n    \"combiner.sparsity\": 0.0001,\n    \"combiner.bn_virtual_bs\": 2048,\n    \"combiner.bn_momentum\": 0.3\n  },\n  \"local_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt\",\n  \"evaluated_params\": {\n    \"combiner.bn_momentum\": 0.3,\n    \"combiner.bn_virtual_bs\": 2048,\n    \"combiner.num_steps\": 4,\n    \"combiner.output_size\": 8,\n    \"combiner.relaxation_factor\": 1.0,\n    \"combiner.size\": 32,\n    \"combiner.sparsity\": 0.0001,\n    \"trainer.batch_size\": 2048,\n    \"trainer.decay_rate\": 0.95,\n    \"trainer.decay_steps\": 500,\n    \"trainer.learning_rate\": 0.025\n  },\n  \"experiment_tag\": \"1_combiner_bn_momentum=0.3000,combiner_bn_virtual_bs=2048,combiner_num_steps=4,combiner_output_size=8,combiner_relaxation_factor=1.0000,combiner_size=32,combiner_sparsity=0.0001,trainer_batch_size=2048,trainer_decay_rate=0.9500,trainer_decay_steps=500,trainer_learning_rate=0.0250\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595a6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 1,\n  \"_last_result\": {\n    \"parameters\": \"{\\\"trainer.learning_rate\\\": 0.025, \\\"trainer.batch_size\\\": 2048, \\\"trainer.decay_rate\\\": 0.95, \\\"trainer.decay_steps\\\": 500, \\\"combiner.size\\\": 32, \\\"combiner.output_size\\\": 8, \\\"combiner.num_steps\\\": 4, \\\"combiner.relaxation_factor\\\": 1.0, \\\"combiner.sparsity\\\": 0.0001, \\\"combiner.bn_virtual_bs\\\": 2048, \\\"combiner.bn_momentum\\\": 0.3}\",\n    \"metric_score\": 0.9855267405509949,\n    \"training_stats\": \"{\\\"training\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.26627808809280396, 0.17989811301231384, 0.12115166336297989, 0.07643859088420868, 0.07997114956378937], \\\"roc_auc\\\": [0.8082901835441589, 0.9299538731575012, 0.9707050919532776, 0.9881786704063416, 0.9868959188461304], \\\"accuracy\\\": [0.9040465354919434, 0.9111023545265198, 0.9421230554580688, 0.9679421782493591, 0.9666378498077393]}, \\\"combined\\\": {\\\"loss\\\": [0.26635212112159934, 0.1799658554009511, 0.12121414756256854, 0.0764979083869548, 0.08002903026499553]}}, \\\"validation\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.25994959473609924, 0.18330249190330505, 0.12807932496070862, 0.08347399532794952, 0.0864425078034401], \\\"roc_auc\\\": [0.8111209869384766, 0.9231897592544556, 0.9638838768005371, 0.9855267405509949, 0.9835507869720459], \\\"accuracy\\\": [0.9016321301460266, 0.9075871109962463, 0.9359285235404968, 0.96471107006073, 0.9627260565757751]}, \\\"combined\\\": {\\\"loss\\\": [0.2600237323276815, 0.18336968552466715, 0.12814138604153413, 0.08353304961929098, 0.08650029308046214]}}, \\\"test\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.27491962909698486, 0.18570367991924286, 0.13252046704292297, 0.08754168450832367, 0.08844424039125443], \\\"roc_auc\\\": [0.8127028942108154, 0.9286696314811707, 0.9663209319114685, 0.9850084185600281, 0.9834038019180298], \\\"accuracy\\\": [0.8983621001243591, 0.9044835567474365, 0.9355870485305786, 0.9636574387550354, 0.9637125730514526]}, \\\"combined\\\": {\\\"loss\\\": [0.2749938599736197, 0.18577003858808894, 0.13258185517042875, 0.08760031849669758, 0.08850186522249714]}}}\",\n    \"eval_stats\": \"{}\",\n    \"trial_id\": \"bb6a6854\",\n    \"trial_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_bb6a6854/\",\n    \"time_this_iter_s\": 21.308068990707397,\n    \"should_checkpoint\": true,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 5,\n    \"experiment_id\": \"63a865f9a080414e8bb1d003d886f264\",\n    \"date\": \"2022-06-29_18-29-52\",\n    \"timestamp\": 1656541792,\n    \"time_total_s\": 108.23516392707825,\n    \"pid\": 72855,\n    \"hostname\": \"C02FR8FUMD6R.grubhub.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"trainer.learning_rate\": 0.025,\n      \"trainer.batch_size\": 2048,\n      \"trainer.decay_rate\": 0.95,\n      \"trainer.decay_steps\": 500,\n      \"combiner.size\": 32,\n      \"combiner.output_size\": 8,\n      \"combiner.num_steps\": 4,\n      \"combiner.relaxation_factor\": 1.0,\n      \"combiner.sparsity\": 0.0001,\n      \"combiner.bn_virtual_bs\": 2048,\n      \"combiner.bn_momentum\": 0.3\n    },\n    \"time_since_restore\": 108.23516392707825,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 5,\n    \"warmup_time\": 0.0022389888763427734,\n    \"experiment_tag\": \"1_combiner_bn_momentum=0.3000,combiner_bn_virtual_bs=2048,combiner_num_steps=4,combiner_output_size=8,combiner_relaxation_factor=1.0000,combiner_size=32,combiner_sparsity=0.0001,trainer_batch_size=2048,trainer_decay_rate=0.9500,trainer_decay_steps=500,trainer_learning_rate=0.0250\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1656541792.148332,\n  \"metric_analysis\": {\n    \"metric_score\": {\n      \"max\": 0.9855267405509949,\n      \"min\": 0.8111209869384766,\n      \"avg\": 0.9338496208190918,\n      \"last\": 0.9855267405509949,\n      \"last-5-avg\": 0.9338496208190918,\n      \"last-10-avg\": 0.9338496208190918\n    },\n    \"time_this_iter_s\": {\n      \"max\": 28.20042133331299,\n      \"min\": 13.753952026367188,\n      \"avg\": 21.64703278541565,\n      \"last\": 21.308068990707397,\n      \"last-5-avg\": 21.64703278541565,\n      \"last-10-avg\": 21.64703278541565\n    },\n    \"should_checkpoint\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": 1.0,\n      \"last\": true,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 5,\n      \"min\": 1,\n      \"avg\": 3.0,\n      \"last\": 5,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    },\n    \"time_total_s\": {\n      \"max\": 108.23516392707825,\n      \"min\": 13.753952026367188,\n      \"avg\": 61.935503530502324,\n      \"last\": 108.23516392707825,\n      \"last-5-avg\": 61.93550353050232,\n      \"last-10-avg\": 61.93550353050232\n    },\n    \"time_since_restore\": {\n      \"max\": 108.23516392707825,\n      \"min\": 13.753952026367188,\n      \"avg\": 61.935503530502324,\n      \"last\": 108.23516392707825,\n      \"last-5-avg\": 61.93550353050232,\n      \"last-10-avg\": 61.93550353050232\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 5,\n      \"min\": 1,\n      \"avg\": 3.0,\n      \"last\": 5,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    },\n    \"warmup_time\": {\n      \"max\": 0.0022389888763427734,\n      \"min\": 0.0022389888763427734,\n      \"avg\": 0.0022389888763427734,\n      \"last\": 0.0022389888763427734,\n      \"last-5-avg\": 0.0022389888763427734,\n      \"last-10-avg\": 0.0022389888763427734\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"metric_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe9f4b400000000473fed8ac540000000473feed82300000000473fef896f60000000473fef896f60000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe9f4b400000000473fed8ac540000000473feed82300000000473fef896f60000000473fef896f60000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847402b82060000000047403686c81800000047403c334ed0000000474036723c300000004740354edd9c000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847402b82060000000047403686c81800000047403c334ed0000000474036723c300000004740354edd9c000000652e\"\n      }\n    },\n    \"should_checkpoint\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288888888888652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288888888888652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b034b044b05652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b05652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847402b82060000000047404223e58c0000004740501ec67a000000474055bb558600000047405b0f0ced000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847402b82060000000047404223e58c0000004740501ec67a000000474055bb558600000047405b0f0ced000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847402b82060000000047404223e58c0000004740501ec67a000000474055bb558600000047405b0f0ced000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847402b82060000000047404223e58c0000004740501ec67a000000474055bb558600000047405b0f0ced000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b034b044b05652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b05652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f62578000000000473f62578000000000473f62578000000000473f62578000000000473f62578000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f62578000000000473f62578000000000473f62578000000000473f62578000000000473f62578000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1656541680.1426601,\n  \"logdir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_bb6a6854\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd2024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd3024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": \"trial_bb6a6854\",\n  \"custom_dirname\": \"trial_bb6a6854\",\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": 1,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"trainable_func_f2we_ZX\",\n  \"trial_id\": \"bdd9150e\",\n  \"config\": {\n    \"trainer.learning_rate\": 0.01,\n    \"trainer.batch_size\": 256,\n    \"trainer.decay_rate\": 0.9,\n    \"trainer.decay_steps\": 10000,\n    \"combiner.size\": 64,\n    \"combiner.output_size\": 24,\n    \"combiner.num_steps\": 7,\n    \"combiner.relaxation_factor\": 1.5,\n    \"combiner.sparsity\": 0.0,\n    \"combiner.bn_virtual_bs\": 4096,\n    \"combiner.bn_momentum\": 0.1\n  },\n  \"local_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt\",\n  \"evaluated_params\": {\n    \"combiner.bn_momentum\": 0.1,\n    \"combiner.bn_virtual_bs\": 4096,\n    \"combiner.num_steps\": 7,\n    \"combiner.output_size\": 24,\n    \"combiner.relaxation_factor\": 1.5,\n    \"combiner.size\": 64,\n    \"combiner.sparsity\": 0.0,\n    \"trainer.batch_size\": 256,\n    \"trainer.decay_rate\": 0.9,\n    \"trainer.decay_steps\": 10000,\n    \"trainer.learning_rate\": 0.01\n  },\n  \"experiment_tag\": \"8_combiner_bn_momentum=0.1000,combiner_bn_virtual_bs=4096,combiner_num_steps=7,combiner_output_size=24,combiner_relaxation_factor=1.5000,combiner_size=64,combiner_sparsity=0.0000,trainer_batch_size=256,trainer_decay_rate=0.9000,trainer_decay_steps=10000,trainer_learning_rate=0.0100\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595a6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 1,\n  \"_last_result\": {\n    \"parameters\": \"{\\\"trainer.learning_rate\\\": 0.01, \\\"trainer.batch_size\\\": 256, \\\"trainer.decay_rate\\\": 0.9, \\\"trainer.decay_steps\\\": 10000, \\\"combiner.size\\\": 64, \\\"combiner.output_size\\\": 24, \\\"combiner.num_steps\\\": 7, \\\"combiner.relaxation_factor\\\": 1.5, \\\"combiner.sparsity\\\": 0.0, \\\"combiner.bn_virtual_bs\\\": 4096, \\\"combiner.bn_momentum\\\": 0.1}\",\n    \"metric_score\": 0.8392467498779297,\n    \"training_stats\": \"{\\\"training\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.24633096158504486], \\\"roc_auc\\\": [0.8395981192588806], \\\"accuracy\\\": [0.9016422033309937]}, \\\"combined\\\": {\\\"loss\\\": [0.24633096158504486]}}, \\\"validation\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.2513847053050995], \\\"roc_auc\\\": [0.8392467498779297], \\\"accuracy\\\": [0.8976621031761169]}, \\\"combined\\\": {\\\"loss\\\": [0.2513847053050995]}}, \\\"test\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.25711479783058167], \\\"roc_auc\\\": [0.8384526968002319], \\\"accuracy\\\": [0.8954944014549255]}, \\\"combined\\\": {\\\"loss\\\": [0.25711479783058167]}}}\",\n    \"eval_stats\": \"{}\",\n    \"trial_id\": \"bdd9150e\",\n    \"trial_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_bdd9150e/\",\n    \"time_this_iter_s\": 77.88170385360718,\n    \"should_checkpoint\": true,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"experiment_id\": \"e2417c08e48847778013adedc443d767\",\n    \"date\": \"2022-06-29_18-29-30\",\n    \"timestamp\": 1656541770,\n    \"time_total_s\": 77.88170385360718,\n    \"pid\": 72877,\n    \"hostname\": \"C02FR8FUMD6R.grubhub.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"trainer.learning_rate\": 0.01,\n      \"trainer.batch_size\": 256,\n      \"trainer.decay_rate\": 0.9,\n      \"trainer.decay_steps\": 10000,\n      \"combiner.size\": 64,\n      \"combiner.output_size\": 24,\n      \"combiner.num_steps\": 7,\n      \"combiner.relaxation_factor\": 1.5,\n      \"combiner.sparsity\": 0.0,\n      \"combiner.bn_virtual_bs\": 4096,\n      \"combiner.bn_momentum\": 0.1\n    },\n    \"time_since_restore\": 77.88170385360718,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.004250049591064453,\n    \"experiment_tag\": \"8_combiner_bn_momentum=0.1000,combiner_bn_virtual_bs=4096,combiner_num_steps=7,combiner_output_size=24,combiner_relaxation_factor=1.5000,combiner_size=64,combiner_sparsity=0.0000,trainer_batch_size=256,trainer_decay_rate=0.9000,trainer_decay_steps=10000,trainer_learning_rate=0.0100\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1656541770.569825,\n  \"metric_analysis\": {\n    \"metric_score\": {\n      \"max\": 0.8392467498779297,\n      \"min\": 0.8392467498779297,\n      \"avg\": 0.8392467498779297,\n      \"last\": 0.8392467498779297,\n      \"last-5-avg\": 0.8392467498779297,\n      \"last-10-avg\": 0.8392467498779297\n    },\n    \"time_this_iter_s\": {\n      \"max\": 77.88170385360718,\n      \"min\": 77.88170385360718,\n      \"avg\": 77.88170385360718,\n      \"last\": 77.88170385360718,\n      \"last-5-avg\": 77.88170385360718,\n      \"last-10-avg\": 77.88170385360718\n    },\n    \"should_checkpoint\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 77.88170385360718,\n      \"min\": 77.88170385360718,\n      \"avg\": 77.88170385360718,\n      \"last\": 77.88170385360718,\n      \"last-5-avg\": 77.88170385360718,\n      \"last-10-avg\": 77.88170385360718\n    },\n    \"time_since_restore\": {\n      \"max\": 77.88170385360718,\n      \"min\": 77.88170385360718,\n      \"avg\": 77.88170385360718,\n      \"last\": 77.88170385360718,\n      \"last-5-avg\": 77.88170385360718,\n      \"last-10-avg\": 77.88170385360718\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.004250049591064453,\n      \"min\": 0.004250049591064453,\n      \"avg\": 0.004250049591064453,\n      \"last\": 0.004250049591064453,\n      \"last-5-avg\": 0.004250049591064453,\n      \"last-10-avg\": 0.004250049591064453\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"metric_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473feadb1c00000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473feadb1c00000000612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474053786dd6000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474053786dd6000000612e\"\n      }\n    },\n    \"should_checkpoint\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474053786dd6000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474053786dd6000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294474053786dd6000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294474053786dd6000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f71688000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f71688000000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1656541684.088991,\n  \"logdir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_bdd9150e\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd2024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd3024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": \"trial_bdd9150e\",\n  \"custom_dirname\": \"trial_bdd9150e\",\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": 1,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"trainable_func_f2we_ZX\",\n  \"trial_id\": \"bdd488a4\",\n  \"config\": {\n    \"trainer.learning_rate\": 0.025,\n    \"trainer.batch_size\": 1024,\n    \"trainer.decay_rate\": 0.95,\n    \"trainer.decay_steps\": 10000,\n    \"combiner.size\": 8,\n    \"combiner.output_size\": 32,\n    \"combiner.num_steps\": 5,\n    \"combiner.relaxation_factor\": 2.0,\n    \"combiner.sparsity\": 0.0,\n    \"combiner.bn_virtual_bs\": 512,\n    \"combiner.bn_momentum\": 0.4\n  },\n  \"local_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt\",\n  \"evaluated_params\": {\n    \"combiner.bn_momentum\": 0.4,\n    \"combiner.bn_virtual_bs\": 512,\n    \"combiner.num_steps\": 5,\n    \"combiner.output_size\": 32,\n    \"combiner.relaxation_factor\": 2.0,\n    \"combiner.size\": 8,\n    \"combiner.sparsity\": 0.0,\n    \"trainer.batch_size\": 1024,\n    \"trainer.decay_rate\": 0.95,\n    \"trainer.decay_steps\": 10000,\n    \"trainer.learning_rate\": 0.025\n  },\n  \"experiment_tag\": \"7_combiner_bn_momentum=0.4000,combiner_bn_virtual_bs=512,combiner_num_steps=5,combiner_output_size=32,combiner_relaxation_factor=2.0000,combiner_size=8,combiner_sparsity=0.0000,trainer_batch_size=1024,trainer_decay_rate=0.9500,trainer_decay_steps=10000,trainer_learning_rate=0.0250\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595a6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 1,\n  \"_last_result\": {\n    \"parameters\": \"{\\\"trainer.learning_rate\\\": 0.025, \\\"trainer.batch_size\\\": 1024, \\\"trainer.decay_rate\\\": 0.95, \\\"trainer.decay_steps\\\": 10000, \\\"combiner.size\\\": 8, \\\"combiner.output_size\\\": 32, \\\"combiner.num_steps\\\": 5, \\\"combiner.relaxation_factor\\\": 2.0, \\\"combiner.sparsity\\\": 0.0, \\\"combiner.bn_virtual_bs\\\": 512, \\\"combiner.bn_momentum\\\": 0.4}\",\n    \"metric_score\": 0.9546341300010681,\n    \"training_stats\": \"{\\\"training\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.30893632769584656, 0.19582395255565643, 0.1541995108127594], \\\"roc_auc\\\": [0.8242508172988892, 0.9065142869949341, 0.9600653052330017], \\\"accuracy\\\": [0.867415726184845, 0.9018150568008423, 0.9390272498130798]}, \\\"combined\\\": {\\\"loss\\\": [0.30893632769584656, 0.19582395255565643, 0.1541995108127594]}}, \\\"validation\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.30453622341156006, 0.19444483518600464, 0.16034649312496185], \\\"roc_auc\\\": [0.8434162735939026, 0.9087686538696289, 0.9546341300010681], \\\"accuracy\\\": [0.8699823617935181, 0.8995368480682373, 0.9335024356842041]}, \\\"combined\\\": {\\\"loss\\\": [0.30453622341156006, 0.19444483518600464, 0.16034649312496185]}}, \\\"test\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.3077892065048218, 0.1983390897512436, 0.16003578901290894], \\\"roc_auc\\\": [0.823287844657898, 0.9091353416442871, 0.9562329649925232], \\\"accuracy\\\": [0.8637291193008423, 0.8973143100738525, 0.9316163659095764]}, \\\"combined\\\": {\\\"loss\\\": [0.3077892065048218, 0.1983390897512436, 0.16003578901290894]}}}\",\n    \"eval_stats\": \"{}\",\n    \"trial_id\": \"bdd488a4\",\n    \"trial_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_bdd488a4/\",\n    \"time_this_iter_s\": 26.285743951797485,\n    \"should_checkpoint\": true,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 3,\n    \"experiment_id\": \"c8d083aa79004ea3b5fb6af71399f165\",\n    \"date\": \"2022-06-29_18-29-36\",\n    \"timestamp\": 1656541776,\n    \"time_total_s\": 83.45226001739502,\n    \"pid\": 72875,\n    \"hostname\": \"C02FR8FUMD6R.grubhub.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"trainer.learning_rate\": 0.025,\n      \"trainer.batch_size\": 1024,\n      \"trainer.decay_rate\": 0.95,\n      \"trainer.decay_steps\": 10000,\n      \"combiner.size\": 8,\n      \"combiner.output_size\": 32,\n      \"combiner.num_steps\": 5,\n      \"combiner.relaxation_factor\": 2.0,\n      \"combiner.sparsity\": 0.0,\n      \"combiner.bn_virtual_bs\": 512,\n      \"combiner.bn_momentum\": 0.4\n    },\n    \"time_since_restore\": 83.45226001739502,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 3,\n    \"warmup_time\": 0.004537820816040039,\n    \"experiment_tag\": \"7_combiner_bn_momentum=0.4000,combiner_bn_virtual_bs=512,combiner_num_steps=5,combiner_output_size=32,combiner_relaxation_factor=2.0000,combiner_size=8,combiner_sparsity=0.0000,trainer_batch_size=1024,trainer_decay_rate=0.9500,trainer_decay_steps=10000,trainer_learning_rate=0.0250\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1656541776.138518,\n  \"metric_analysis\": {\n    \"metric_score\": {\n      \"max\": 0.9546341300010681,\n      \"min\": 0.8434162735939026,\n      \"avg\": 0.9022730191548665,\n      \"last\": 0.9546341300010681,\n      \"last-5-avg\": 0.9022730191548666,\n      \"last-10-avg\": 0.9022730191548666\n    },\n    \"time_this_iter_s\": {\n      \"max\": 32.07544302940369,\n      \"min\": 25.091073036193848,\n      \"avg\": 27.81742000579834,\n      \"last\": 26.285743951797485,\n      \"last-5-avg\": 27.81742000579834,\n      \"last-10-avg\": 27.81742000579834\n    },\n    \"should_checkpoint\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": 1.0,\n      \"last\": true,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.3333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.3333333333333333,\n      \"last-10-avg\": 0.3333333333333333\n    },\n    \"training_iteration\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"time_total_s\": {\n      \"max\": 83.45226001739502,\n      \"min\": 25.091073036193848,\n      \"avg\": 55.236616373062134,\n      \"last\": 83.45226001739502,\n      \"last-5-avg\": 55.236616373062134,\n      \"last-10-avg\": 55.236616373062134\n    },\n    \"time_since_restore\": {\n      \"max\": 83.45226001739502,\n      \"min\": 25.091073036193848,\n      \"avg\": 55.236616373062134,\n      \"last\": 83.45226001739502,\n      \"last-5-avg\": 55.236616373062134,\n      \"last-10-avg\": 55.236616373062134\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"warmup_time\": {\n      \"max\": 0.004537820816040039,\n      \"min\": 0.004537820816040039,\n      \"avg\": 0.004537820816040039,\n      \"last\": 0.004537820816040039,\n      \"last-5-avg\": 0.004537820816040039,\n      \"last-10-avg\": 0.004537820816040039\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"metric_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473feafd4420000000473fed14a200000000473fee8c5ce0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473feafd4420000000473fed14a200000000473fee8c5ce0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403917509000000047404009a81e00000047403a492684000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403917509000000047404009a81e00000047403a492684000000652e\"\n      }\n    },\n    \"should_checkpoint\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428888888652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428888888652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403917509000000047404c955066000000474054dcf1d4000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403917509000000047404c955066000000474054dcf1d4000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403917509000000047404c955066000000474054dcf1d4000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403917509000000047404c955066000000474054dcf1d4000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f72964000000000473f72964000000000473f72964000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f72964000000000473f72964000000000473f72964000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1656541684.0616949,\n  \"logdir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_bdd488a4\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd2024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd3024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": \"trial_bdd488a4\",\n  \"custom_dirname\": \"trial_bdd488a4\",\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": 1,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"trainable_func_f2we_ZX\",\n  \"trial_id\": \"bdc64f96\",\n  \"config\": {\n    \"trainer.learning_rate\": 0.01,\n    \"trainer.batch_size\": 256,\n    \"trainer.decay_rate\": 0.95,\n    \"trainer.decay_steps\": 20000,\n    \"combiner.size\": 8,\n    \"combiner.output_size\": 24,\n    \"combiner.num_steps\": 7,\n    \"combiner.relaxation_factor\": 2.0,\n    \"combiner.sparsity\": 0.001,\n    \"combiner.bn_virtual_bs\": 1024,\n    \"combiner.bn_momentum\": 0.2\n  },\n  \"local_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt\",\n  \"evaluated_params\": {\n    \"combiner.bn_momentum\": 0.2,\n    \"combiner.bn_virtual_bs\": 1024,\n    \"combiner.num_steps\": 7,\n    \"combiner.output_size\": 24,\n    \"combiner.relaxation_factor\": 2.0,\n    \"combiner.size\": 8,\n    \"combiner.sparsity\": 0.001,\n    \"trainer.batch_size\": 256,\n    \"trainer.decay_rate\": 0.95,\n    \"trainer.decay_steps\": 20000,\n    \"trainer.learning_rate\": 0.01\n  },\n  \"experiment_tag\": \"4_combiner_bn_momentum=0.2000,combiner_bn_virtual_bs=1024,combiner_num_steps=7,combiner_output_size=24,combiner_relaxation_factor=2.0000,combiner_size=8,combiner_sparsity=0.0010,trainer_batch_size=256,trainer_decay_rate=0.9500,trainer_decay_steps=20000,trainer_learning_rate=0.0100\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595a6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 1,\n  \"_last_result\": {\n    \"parameters\": \"{\\\"trainer.learning_rate\\\": 0.01, \\\"trainer.batch_size\\\": 256, \\\"trainer.decay_rate\\\": 0.95, \\\"trainer.decay_steps\\\": 20000, \\\"combiner.size\\\": 8, \\\"combiner.output_size\\\": 24, \\\"combiner.num_steps\\\": 7, \\\"combiner.relaxation_factor\\\": 2.0, \\\"combiner.sparsity\\\": 0.001, \\\"combiner.bn_virtual_bs\\\": 1024, \\\"combiner.bn_momentum\\\": 0.2}\",\n    \"metric_score\": 0.9181011915206909,\n    \"training_stats\": \"{\\\"training\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.33140063285827637, 0.1817169189453125], \\\"roc_auc\\\": [0.7578039169311523, 0.9262746572494507], \\\"accuracy\\\": [0.9040465354919434, 0.9124380946159363]}, \\\"combined\\\": {\\\"loss\\\": [0.3316989227896556, 0.18193603461259045]}}, \\\"validation\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.3332042098045349, 0.1913660317659378], \\\"roc_auc\\\": [0.763691246509552, 0.9181011915206909], \\\"accuracy\\\": [0.9016321301460266, 0.9084693193435669]}, \\\"combined\\\": {\\\"loss\\\": [0.33350243273889646, 0.1915788106562104]}}, \\\"test\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.3458561599254608, 0.19425998628139496], \\\"roc_auc\\\": [0.757211446762085, 0.9187569618225098], \\\"accuracy\\\": [0.8983621001243591, 0.9047041535377502]}, \\\"combined\\\": {\\\"loss\\\": [0.3461546221515164, 0.19446226255968213]}}}\",\n    \"eval_stats\": \"{}\",\n    \"trial_id\": \"bdc64f96\",\n    \"trial_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_bdc64f96/\",\n    \"time_this_iter_s\": 45.71811318397522,\n    \"should_checkpoint\": true,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 2,\n    \"experiment_id\": \"fc4d25b5901f476eb3e0cbfc45595477\",\n    \"date\": \"2022-06-29_18-29-48\",\n    \"timestamp\": 1656541788,\n    \"time_total_s\": 96.05996632575989,\n    \"pid\": 72867,\n    \"hostname\": \"C02FR8FUMD6R.grubhub.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"trainer.learning_rate\": 0.01,\n      \"trainer.batch_size\": 256,\n      \"trainer.decay_rate\": 0.95,\n      \"trainer.decay_steps\": 20000,\n      \"combiner.size\": 8,\n      \"combiner.output_size\": 24,\n      \"combiner.num_steps\": 7,\n      \"combiner.relaxation_factor\": 2.0,\n      \"combiner.sparsity\": 0.001,\n      \"combiner.bn_virtual_bs\": 1024,\n      \"combiner.bn_momentum\": 0.2\n    },\n    \"time_since_restore\": 96.05996632575989,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 2,\n    \"warmup_time\": 0.004129886627197266,\n    \"experiment_tag\": \"4_combiner_bn_momentum=0.2000,combiner_bn_virtual_bs=1024,combiner_num_steps=7,combiner_output_size=24,combiner_relaxation_factor=2.0000,combiner_size=8,combiner_sparsity=0.0010,trainer_batch_size=256,trainer_decay_rate=0.9500,trainer_decay_steps=20000,trainer_learning_rate=0.0100\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1656541788.121779,\n  \"metric_analysis\": {\n    \"metric_score\": {\n      \"max\": 0.9181011915206909,\n      \"min\": 0.763691246509552,\n      \"avg\": 0.8408962190151215,\n      \"last\": 0.9181011915206909,\n      \"last-5-avg\": 0.8408962190151215,\n      \"last-10-avg\": 0.8408962190151215\n    },\n    \"time_this_iter_s\": {\n      \"max\": 50.34185314178467,\n      \"min\": 45.71811318397522,\n      \"avg\": 48.029983162879944,\n      \"last\": 45.71811318397522,\n      \"last-5-avg\": 48.029983162879944,\n      \"last-10-avg\": 48.029983162879944\n    },\n    \"should_checkpoint\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": 1.0,\n      \"last\": true,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_total_s\": {\n      \"max\": 96.05996632575989,\n      \"min\": 50.34185314178467,\n      \"avg\": 73.20090973377228,\n      \"last\": 96.05996632575989,\n      \"last-5-avg\": 73.20090973377228,\n      \"last-10-avg\": 73.20090973377228\n    },\n    \"time_since_restore\": {\n      \"max\": 96.05996632575989,\n      \"min\": 50.34185314178467,\n      \"avg\": 73.20090973377228,\n      \"last\": 96.05996632575989,\n      \"last-5-avg\": 73.20090973377228,\n      \"last-10-avg\": 73.20090973377228\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.004129886627197266,\n      \"min\": 0.004129886627197266,\n      \"avg\": 0.004129886627197266,\n      \"last\": 0.004129886627197266,\n      \"last-5-avg\": 0.004129886627197266,\n      \"last-10-avg\": 0.004129886627197266\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"metric_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe87028a0000000473fed6115c0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe87028a0000000473fed6115c0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740492bc1d8000000474046dbeb22000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740492bc1d8000000474046dbeb22000000652e\"\n      }\n    },\n    \"should_checkpoint\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288888652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288888652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740492bc1d800000047405803d67d000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740492bc1d800000047405803d67d000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740492bc1d800000047405803d67d000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740492bc1d800000047405803d67d000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f70ea8000000000473f70ea8000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f70ea8000000000473f70ea8000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1656541683.9724858,\n  \"logdir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_bdc64f96\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd2024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd3024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": \"trial_bdc64f96\",\n  \"custom_dirname\": \"trial_bdc64f96\",\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": 1,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"trainable_func_f2we_ZX\",\n  \"trial_id\": \"bdcb6684\",\n  \"config\": {\n    \"trainer.learning_rate\": 0.005,\n    \"trainer.batch_size\": 512,\n    \"trainer.decay_rate\": 0.95,\n    \"trainer.decay_steps\": 20000,\n    \"combiner.size\": 64,\n    \"combiner.output_size\": 64,\n    \"combiner.num_steps\": 5,\n    \"combiner.relaxation_factor\": 1.5,\n    \"combiner.sparsity\": 0.0001,\n    \"combiner.bn_virtual_bs\": 256,\n    \"combiner.bn_momentum\": 0.1\n  },\n  \"local_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt\",\n  \"evaluated_params\": {\n    \"combiner.bn_momentum\": 0.1,\n    \"combiner.bn_virtual_bs\": 256,\n    \"combiner.num_steps\": 5,\n    \"combiner.output_size\": 64,\n    \"combiner.relaxation_factor\": 1.5,\n    \"combiner.size\": 64,\n    \"combiner.sparsity\": 0.0001,\n    \"trainer.batch_size\": 512,\n    \"trainer.decay_rate\": 0.95,\n    \"trainer.decay_steps\": 20000,\n    \"trainer.learning_rate\": 0.005\n  },\n  \"experiment_tag\": \"5_combiner_bn_momentum=0.1000,combiner_bn_virtual_bs=256,combiner_num_steps=5,combiner_output_size=64,combiner_relaxation_factor=1.5000,combiner_size=64,combiner_sparsity=0.0001,trainer_batch_size=512,trainer_decay_rate=0.9500,trainer_decay_steps=20000,trainer_learning_rate=0.0050\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595a6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 1,\n  \"_last_result\": {\n    \"parameters\": \"{\\\"trainer.learning_rate\\\": 0.005, \\\"trainer.batch_size\\\": 512, \\\"trainer.decay_rate\\\": 0.95, \\\"trainer.decay_steps\\\": 20000, \\\"combiner.size\\\": 64, \\\"combiner.output_size\\\": 64, \\\"combiner.num_steps\\\": 5, \\\"combiner.relaxation_factor\\\": 1.5, \\\"combiner.sparsity\\\": 0.0001, \\\"combiner.bn_virtual_bs\\\": 256, \\\"combiner.bn_momentum\\\": 0.1}\",\n    \"metric_score\": 0.8900913000106812,\n    \"training_stats\": \"{\\\"training\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.2533119022846222, 0.2063780128955841], \\\"roc_auc\\\": [0.830421507358551, 0.8929733037948608], \\\"accuracy\\\": [0.9033393859863281, 0.9031036496162415]}, \\\"combined\\\": {\\\"loss\\\": [0.2533555643640284, 0.20641830653403304]}}, \\\"validation\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.26515889167785645, 0.21037200093269348], \\\"roc_auc\\\": [0.8184343576431274, 0.8900913000106812], \\\"accuracy\\\": [0.8992059826850891, 0.9000882506370544]}, \\\"combined\\\": {\\\"loss\\\": [0.26520254850765923, 0.2104120477270044]}}, \\\"test\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.2612825930118561, 0.21498972177505493], \\\"roc_auc\\\": [0.8336548805236816, 0.8897092342376709], \\\"accuracy\\\": [0.8990790247917175, 0.8975900411605835]}, \\\"combined\\\": {\\\"loss\\\": [0.2613262640115863, 0.21502931974464445]}}}\",\n    \"eval_stats\": \"{}\",\n    \"trial_id\": \"bdcb6684\",\n    \"trial_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_bdcb6684/\",\n    \"time_this_iter_s\": 50.198556900024414,\n    \"should_checkpoint\": true,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 2,\n    \"experiment_id\": \"82271e84860242c0945d5549fb2d4c92\",\n    \"date\": \"2022-06-29_18-30-00\",\n    \"timestamp\": 1656541800,\n    \"time_total_s\": 108.2431070804596,\n    \"pid\": 72869,\n    \"hostname\": \"C02FR8FUMD6R.grubhub.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"trainer.learning_rate\": 0.005,\n      \"trainer.batch_size\": 512,\n      \"trainer.decay_rate\": 0.95,\n      \"trainer.decay_steps\": 20000,\n      \"combiner.size\": 64,\n      \"combiner.output_size\": 64,\n      \"combiner.num_steps\": 5,\n      \"combiner.relaxation_factor\": 1.5,\n      \"combiner.sparsity\": 0.0001,\n      \"combiner.bn_virtual_bs\": 256,\n      \"combiner.bn_momentum\": 0.1\n    },\n    \"time_since_restore\": 108.2431070804596,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 2,\n    \"warmup_time\": 0.004297018051147461,\n    \"experiment_tag\": \"5_combiner_bn_momentum=0.1000,combiner_bn_virtual_bs=256,combiner_num_steps=5,combiner_output_size=64,combiner_relaxation_factor=1.5000,combiner_size=64,combiner_sparsity=0.0001,trainer_batch_size=512,trainer_decay_rate=0.9500,trainer_decay_steps=20000,trainer_learning_rate=0.0050\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1656541800.3094232,\n  \"metric_analysis\": {\n    \"metric_score\": {\n      \"max\": 0.8900913000106812,\n      \"min\": 0.8184343576431274,\n      \"avg\": 0.8542628288269043,\n      \"last\": 0.8900913000106812,\n      \"last-5-avg\": 0.8542628288269043,\n      \"last-10-avg\": 0.8542628288269043\n    },\n    \"time_this_iter_s\": {\n      \"max\": 58.04455018043518,\n      \"min\": 50.198556900024414,\n      \"avg\": 54.1215535402298,\n      \"last\": 50.198556900024414,\n      \"last-5-avg\": 54.1215535402298,\n      \"last-10-avg\": 54.1215535402298\n    },\n    \"should_checkpoint\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": 1.0,\n      \"last\": true,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_total_s\": {\n      \"max\": 108.2431070804596,\n      \"min\": 58.04455018043518,\n      \"avg\": 83.14382863044739,\n      \"last\": 108.2431070804596,\n      \"last-5-avg\": 83.14382863044739,\n      \"last-10-avg\": 83.14382863044739\n    },\n    \"time_since_restore\": {\n      \"max\": 108.2431070804596,\n      \"min\": 58.04455018043518,\n      \"avg\": 83.14382863044739,\n      \"last\": 108.2431070804596,\n      \"last-5-avg\": 83.14382863044739,\n      \"last-10-avg\": 83.14382863044739\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"warmup_time\": {\n      \"max\": 0.004297018051147461,\n      \"min\": 0.004297018051147461,\n      \"avg\": 0.004297018051147461,\n      \"last\": 0.004297018051147461,\n      \"last-5-avg\": 0.004297018051147461,\n      \"last-10-avg\": 0.004297018051147461\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"metric_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fea309d40000000473fec7ba0c0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fea309d40000000473fec7ba0c0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404d05b3d2000000474049196a50000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404d05b3d2000000474049196a50000000652e\"\n      }\n    },\n    \"should_checkpoint\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288888652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288888652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404d05b3d200000047405b0f8f11000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404d05b3d200000047405b0f8f11000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404d05b3d200000047405b0f8f11000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404d05b3d200000047405b0f8f11000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f7199c000000000473f7199c000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f7199c000000000473f7199c000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1656541684.0005708,\n  \"logdir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_bdcb6684\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd2024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd3024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": \"trial_bdcb6684\",\n  \"custom_dirname\": \"trial_bdcb6684\",\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": 1,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"trainable_func_f2we_ZX\",\n  \"trial_id\": \"bddd2b9e\",\n  \"config\": {\n    \"trainer.learning_rate\": 0.005,\n    \"trainer.batch_size\": 1024,\n    \"trainer.decay_rate\": 0.95,\n    \"trainer.decay_steps\": 2000,\n    \"combiner.size\": 64,\n    \"combiner.output_size\": 16,\n    \"combiner.num_steps\": 3,\n    \"combiner.relaxation_factor\": 1.2,\n    \"combiner.sparsity\": 0.001,\n    \"combiner.bn_virtual_bs\": 256,\n    \"combiner.bn_momentum\": 0.2\n  },\n  \"local_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt\",\n  \"evaluated_params\": {\n    \"combiner.bn_momentum\": 0.2,\n    \"combiner.bn_virtual_bs\": 256,\n    \"combiner.num_steps\": 3,\n    \"combiner.output_size\": 16,\n    \"combiner.relaxation_factor\": 1.2,\n    \"combiner.size\": 64,\n    \"combiner.sparsity\": 0.001,\n    \"trainer.batch_size\": 1024,\n    \"trainer.decay_rate\": 0.95,\n    \"trainer.decay_steps\": 2000,\n    \"trainer.learning_rate\": 0.005\n  },\n  \"experiment_tag\": \"9_combiner_bn_momentum=0.2000,combiner_bn_virtual_bs=256,combiner_num_steps=3,combiner_output_size=16,combiner_relaxation_factor=1.2000,combiner_size=64,combiner_sparsity=0.0010,trainer_batch_size=1024,trainer_decay_rate=0.9500,trainer_decay_steps=2000,trainer_learning_rate=0.0050\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595a6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 1,\n  \"_last_result\": {\n    \"parameters\": \"{\\\"trainer.learning_rate\\\": 0.005, \\\"trainer.batch_size\\\": 1024, \\\"trainer.decay_rate\\\": 0.95, \\\"trainer.decay_steps\\\": 2000, \\\"combiner.size\\\": 64, \\\"combiner.output_size\\\": 16, \\\"combiner.num_steps\\\": 3, \\\"combiner.relaxation_factor\\\": 1.2, \\\"combiner.sparsity\\\": 0.001, \\\"combiner.bn_virtual_bs\\\": 256, \\\"combiner.bn_momentum\\\": 0.2}\",\n    \"metric_score\": 0.9357465505599976,\n    \"training_stats\": \"{\\\"training\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.24512799084186554, 0.17811575531959534, 0.16127733886241913], \\\"roc_auc\\\": [0.8396567106246948, 0.9269633293151855, 0.9450514912605286], \\\"accuracy\\\": [0.904360830783844, 0.9074879884719849, 0.9214111566543579]}, \\\"combined\\\": {\\\"loss\\\": [0.24579900514800102, 0.1787721262080595, 0.16192077210871503]}}, \\\"validation\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.25019383430480957, 0.18238691985607147, 0.1745680868625641], \\\"roc_auc\\\": [0.8347501754760742, 0.9239571690559387, 0.9357465505599976], \\\"accuracy\\\": [0.9013012647628784, 0.9053815603256226, 0.9144243597984314]}, \\\"combined\\\": {\\\"loss\\\": [0.2508641980821267, 0.18304208246991038, 0.17521039285929874]}}, \\\"test\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.2550872564315796, 0.1875327080488205, 0.17313604056835175], \\\"roc_auc\\\": [0.832984983921051, 0.9218736290931702, 0.938619077205658], \\\"accuracy\\\": [0.8981415033340454, 0.9013952612876892, 0.9144101738929749]}, \\\"combined\\\": {\\\"loss\\\": [0.2557588806957938, 0.18818611180176958, 0.17377663764636964]}}}\",\n    \"eval_stats\": \"{}\",\n    \"trial_id\": \"bddd2b9e\",\n    \"trial_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_bddd2b9e/\",\n    \"time_this_iter_s\": 25.974219799041748,\n    \"should_checkpoint\": true,\n    \"done\": true,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 3,\n    \"experiment_id\": \"714dc8c9ad0e4009b11994881ab3a5c1\",\n    \"date\": \"2022-06-29_18-29-33\",\n    \"timestamp\": 1656541773,\n    \"time_total_s\": 81.15509796142578,\n    \"pid\": 72880,\n    \"hostname\": \"C02FR8FUMD6R.grubhub.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"trainer.learning_rate\": 0.005,\n      \"trainer.batch_size\": 1024,\n      \"trainer.decay_rate\": 0.95,\n      \"trainer.decay_steps\": 2000,\n      \"combiner.size\": 64,\n      \"combiner.output_size\": 16,\n      \"combiner.num_steps\": 3,\n      \"combiner.relaxation_factor\": 1.2,\n      \"combiner.sparsity\": 0.001,\n      \"combiner.bn_virtual_bs\": 256,\n      \"combiner.bn_momentum\": 0.2\n    },\n    \"time_since_restore\": 81.15509796142578,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 3,\n    \"warmup_time\": 0.0038471221923828125,\n    \"experiment_tag\": \"9_combiner_bn_momentum=0.2000,combiner_bn_virtual_bs=256,combiner_num_steps=3,combiner_output_size=16,combiner_relaxation_factor=1.2000,combiner_size=64,combiner_sparsity=0.0010,trainer_batch_size=1024,trainer_decay_rate=0.9500,trainer_decay_steps=2000,trainer_learning_rate=0.0050\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1656541773.839791,\n  \"metric_analysis\": {\n    \"metric_score\": {\n      \"max\": 0.9357465505599976,\n      \"min\": 0.8347501754760742,\n      \"avg\": 0.8981512983640034,\n      \"last\": 0.9357465505599976,\n      \"last-5-avg\": 0.8981512983640035,\n      \"last-10-avg\": 0.8981512983640035\n    },\n    \"time_this_iter_s\": {\n      \"max\": 31.561151027679443,\n      \"min\": 23.61972713470459,\n      \"avg\": 27.051699320475258,\n      \"last\": 25.974219799041748,\n      \"last-5-avg\": 27.05169932047526,\n      \"last-10-avg\": 27.05169932047526\n    },\n    \"should_checkpoint\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": 1.0,\n      \"last\": true,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.3333333333333333,\n      \"last\": true,\n      \"last-5-avg\": 0.3333333333333333,\n      \"last-10-avg\": 0.3333333333333333\n    },\n    \"training_iteration\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"time_total_s\": {\n      \"max\": 81.15509796142578,\n      \"min\": 23.61972713470459,\n      \"avg\": 53.318567752838135,\n      \"last\": 81.15509796142578,\n      \"last-5-avg\": 53.318567752838135,\n      \"last-10-avg\": 53.318567752838135\n    },\n    \"time_since_restore\": {\n      \"max\": 81.15509796142578,\n      \"min\": 23.61972713470459,\n      \"avg\": 53.318567752838135,\n      \"last\": 81.15509796142578,\n      \"last-5-avg\": 53.318567752838135,\n      \"last-10-avg\": 53.318567752838135\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 3,\n      \"min\": 1,\n      \"avg\": 2.0,\n      \"last\": 3,\n      \"last-5-avg\": 2.0,\n      \"last-10-avg\": 2.0\n    },\n    \"warmup_time\": {\n      \"max\": 0.0038471221923828125,\n      \"min\": 0.0038471221923828125,\n      \"avg\": 0.0038471221923828125,\n      \"last\": 0.0038471221923828125,\n      \"last-5-avg\": 0.0038471221923828125,\n      \"last-10-avg\": 0.0038471221923828125\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"metric_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473feab64600000000473fed910ea0000000473fedf1a2c0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473feab64600000000473fed910ea0000000473fedf1a2c0000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740379ea67000000047403f8fa798000000474039f96678000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740379ea67000000047403f8fa798000000474039f96678000000652e\"\n      }\n    },\n    \"should_checkpoint\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428888888652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428888888652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428898988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059525000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428898988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740379ea67000000047404b97270400000047405449ed20000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740379ea67000000047404b97270400000047405449ed20000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740379ea67000000047404b97270400000047405449ed20000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740379ea67000000047404b97270400000047405449ed20000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b03652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f6f840000000000473f6f840000000000473f6f840000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f6f840000000000473f6f840000000000473f6f840000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1656541684.121613,\n  \"logdir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_bddd2b9e\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd2024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd3024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": \"trial_bddd2b9e\",\n  \"custom_dirname\": \"trial_bddd2b9e\",\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": 1,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"trainable_func_f2we_ZX\",\n  \"trial_id\": \"bde2376a\",\n  \"config\": {\n    \"trainer.learning_rate\": 0.02,\n    \"trainer.batch_size\": 256,\n    \"trainer.decay_rate\": 0.9,\n    \"trainer.decay_steps\": 8000,\n    \"combiner.size\": 24,\n    \"combiner.output_size\": 16,\n    \"combiner.num_steps\": 9,\n    \"combiner.relaxation_factor\": 1.0,\n    \"combiner.sparsity\": 0.001,\n    \"combiner.bn_virtual_bs\": 512,\n    \"combiner.bn_momentum\": 0.2\n  },\n  \"local_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt\",\n  \"evaluated_params\": {\n    \"combiner.bn_momentum\": 0.2,\n    \"combiner.bn_virtual_bs\": 512,\n    \"combiner.num_steps\": 9,\n    \"combiner.output_size\": 16,\n    \"combiner.relaxation_factor\": 1.0,\n    \"combiner.size\": 24,\n    \"combiner.sparsity\": 0.001,\n    \"trainer.batch_size\": 256,\n    \"trainer.decay_rate\": 0.9,\n    \"trainer.decay_steps\": 8000,\n    \"trainer.learning_rate\": 0.02\n  },\n  \"experiment_tag\": \"10_combiner_bn_momentum=0.2000,combiner_bn_virtual_bs=512,combiner_num_steps=9,combiner_output_size=16,combiner_relaxation_factor=1.0000,combiner_size=24,combiner_sparsity=0.0010,trainer_batch_size=256,trainer_decay_rate=0.9000,trainer_decay_steps=8000,trainer_learning_rate=0.0200\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595a6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 1,\n  \"_last_result\": {\n    \"parameters\": \"{\\\"trainer.learning_rate\\\": 0.02, \\\"trainer.batch_size\\\": 256, \\\"trainer.decay_rate\\\": 0.9, \\\"trainer.decay_steps\\\": 8000, \\\"combiner.size\\\": 24, \\\"combiner.output_size\\\": 16, \\\"combiner.num_steps\\\": 9, \\\"combiner.relaxation_factor\\\": 1.0, \\\"combiner.sparsity\\\": 0.001, \\\"combiner.bn_virtual_bs\\\": 512, \\\"combiner.bn_momentum\\\": 0.2}\",\n    \"metric_score\": 0.8640846014022827,\n    \"training_stats\": \"{\\\"training\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.24986429512500763], \\\"roc_auc\\\": [0.8686361312866211], \\\"accuracy\\\": [0.8980592489242554]}, \\\"combined\\\": {\\\"loss\\\": [0.25042096292600036]}}, \\\"validation\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.257843554019928], \\\"roc_auc\\\": [0.8640846014022827], \\\"accuracy\\\": [0.8992059826850891]}, \\\"combined\\\": {\\\"loss\\\": [0.2584000410279259]}}, \\\"test\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.254751056432724], \\\"roc_auc\\\": [0.8704236149787903], \\\"accuracy\\\": [0.8951635360717773]}, \\\"combined\\\": {\\\"loss\\\": [0.2553080036304891]}}}\",\n    \"eval_stats\": \"{}\",\n    \"trial_id\": \"bde2376a\",\n    \"trial_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_bde2376a/\",\n    \"time_this_iter_s\": 69.9030818939209,\n    \"should_checkpoint\": true,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 1,\n    \"experiment_id\": \"7f4eda8fa6e147faaeb7e56477fa5e05\",\n    \"date\": \"2022-06-29_18-29-22\",\n    \"timestamp\": 1656541762,\n    \"time_total_s\": 69.9030818939209,\n    \"pid\": 72883,\n    \"hostname\": \"C02FR8FUMD6R.grubhub.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"trainer.learning_rate\": 0.02,\n      \"trainer.batch_size\": 256,\n      \"trainer.decay_rate\": 0.9,\n      \"trainer.decay_steps\": 8000,\n      \"combiner.size\": 24,\n      \"combiner.output_size\": 16,\n      \"combiner.num_steps\": 9,\n      \"combiner.relaxation_factor\": 1.0,\n      \"combiner.sparsity\": 0.001,\n      \"combiner.bn_virtual_bs\": 512,\n      \"combiner.bn_momentum\": 0.2\n    },\n    \"time_since_restore\": 69.9030818939209,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 1,\n    \"warmup_time\": 0.003609895706176758,\n    \"experiment_tag\": \"10_combiner_bn_momentum=0.2000,combiner_bn_virtual_bs=512,combiner_num_steps=9,combiner_output_size=16,combiner_relaxation_factor=1.0000,combiner_size=24,combiner_sparsity=0.0010,trainer_batch_size=256,trainer_decay_rate=0.9000,trainer_decay_steps=8000,trainer_learning_rate=0.0200\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1656541762.573477,\n  \"metric_analysis\": {\n    \"metric_score\": {\n      \"max\": 0.8640846014022827,\n      \"min\": 0.8640846014022827,\n      \"avg\": 0.8640846014022827,\n      \"last\": 0.8640846014022827,\n      \"last-5-avg\": 0.8640846014022827,\n      \"last-10-avg\": 0.8640846014022827\n    },\n    \"time_this_iter_s\": {\n      \"max\": 69.9030818939209,\n      \"min\": 69.9030818939209,\n      \"avg\": 69.9030818939209,\n      \"last\": 69.9030818939209,\n      \"last-5-avg\": 69.9030818939209,\n      \"last-10-avg\": 69.9030818939209\n    },\n    \"should_checkpoint\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": false,\n      \"last\": false,\n      \"last-5-avg\": false,\n      \"last-10-avg\": false\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_total_s\": {\n      \"max\": 69.9030818939209,\n      \"min\": 69.9030818939209,\n      \"avg\": 69.9030818939209,\n      \"last\": 69.9030818939209,\n      \"last-5-avg\": 69.9030818939209,\n      \"last-10-avg\": 69.9030818939209\n    },\n    \"time_since_restore\": {\n      \"max\": 69.9030818939209,\n      \"min\": 69.9030818939209,\n      \"avg\": 69.9030818939209,\n      \"last\": 69.9030818939209,\n      \"last-5-avg\": 69.9030818939209,\n      \"last-10-avg\": 69.9030818939209\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0,\n      \"last\": 0,\n      \"last-5-avg\": 0,\n      \"last-10-avg\": 0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"warmup_time\": {\n      \"max\": 0.003609895706176758,\n      \"min\": 0.003609895706176758,\n      \"avg\": 0.003609895706176758,\n      \"last\": 0.003609895706176758,\n      \"last-5-avg\": 0.003609895706176758,\n      \"last-10-avg\": 0.003609895706176758\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"metric_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473feba694c0000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473feba694c0000000612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405179cc18000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405179cc18000000612e\"\n      }\n    },\n    \"should_checkpoint\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529489612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529489612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405179cc18000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405179cc18000000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529447405179cc18000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529447405179cc18000000612e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b00612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b00612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294473f6d928000000000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294473f6d928000000000612e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1656541684.150584,\n  \"logdir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_bde2376a\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd2024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd3024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": \"trial_bde2376a\",\n  \"custom_dirname\": \"trial_bde2376a\",\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": 1,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"stub\": false,\n  \"trainable_name\": \"trainable_func_f2we_ZX\",\n  \"trial_id\": \"bdcfb194\",\n  \"config\": {\n    \"trainer.learning_rate\": 0.005,\n    \"trainer.batch_size\": 512,\n    \"trainer.decay_rate\": 0.9,\n    \"trainer.decay_steps\": 8000,\n    \"combiner.size\": 16,\n    \"combiner.output_size\": 16,\n    \"combiner.num_steps\": 3,\n    \"combiner.relaxation_factor\": 1.2,\n    \"combiner.sparsity\": 0.01,\n    \"combiner.bn_virtual_bs\": 256,\n    \"combiner.bn_momentum\": 0.4\n  },\n  \"local_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt\",\n  \"evaluated_params\": {\n    \"combiner.bn_momentum\": 0.4,\n    \"combiner.bn_virtual_bs\": 256,\n    \"combiner.num_steps\": 3,\n    \"combiner.output_size\": 16,\n    \"combiner.relaxation_factor\": 1.2,\n    \"combiner.size\": 16,\n    \"combiner.sparsity\": 0.01,\n    \"trainer.batch_size\": 512,\n    \"trainer.decay_rate\": 0.9,\n    \"trainer.decay_steps\": 8000,\n    \"trainer.learning_rate\": 0.005\n  },\n  \"experiment_tag\": \"6_combiner_bn_momentum=0.4000,combiner_bn_virtual_bs=256,combiner_num_steps=3,combiner_output_size=16,combiner_relaxation_factor=1.2000,combiner_size=16,combiner_sparsity=0.0100,trainer_batch_size=512,trainer_decay_rate=0.9000,trainer_decay_steps=8000,trainer_learning_rate=0.0050\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595a6000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d948c0343505594473ff000000000000073618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {},\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 1,\n  \"_last_result\": {\n    \"parameters\": \"{\\\"trainer.learning_rate\\\": 0.005, \\\"trainer.batch_size\\\": 512, \\\"trainer.decay_rate\\\": 0.9, \\\"trainer.decay_steps\\\": 8000, \\\"combiner.size\\\": 16, \\\"combiner.output_size\\\": 16, \\\"combiner.num_steps\\\": 3, \\\"combiner.relaxation_factor\\\": 1.2, \\\"combiner.sparsity\\\": 0.01, \\\"combiner.bn_virtual_bs\\\": 256, \\\"combiner.bn_momentum\\\": 0.4}\",\n    \"metric_score\": 0.9842120409011841,\n    \"training_stats\": \"{\\\"training\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.23481234908103943, 0.16789934039115906, 0.12352447956800461, 0.08205988258123398, 0.0661037415266037], \\\"roc_auc\\\": [0.8582466244697571, 0.9391092658042908, 0.9716773629188538, 0.9867356419563293, 0.9915842413902283], \\\"accuracy\\\": [0.9040465354919434, 0.9126895666122437, 0.9458159804344177, 0.9652235507965088, 0.9730965495109558]}, \\\"combined\\\": {\\\"loss\\\": [0.24196831975132227, 0.17340475926175714, 0.12819113535806537, 0.08630837313830853, 0.07001513382419944]}}, \\\"validation\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.23523327708244324, 0.17745670676231384, 0.13859692215919495, 0.09631417691707611, 0.08489210158586502], \\\"roc_auc\\\": [0.8621048927307129, 0.9327791333198547, 0.962490439414978, 0.9808773994445801, 0.9842120409011841], \\\"accuracy\\\": [0.9015218615531921, 0.9075871109962463, 0.9367004632949829, 0.9580944180488586, 0.9670268893241882]}, \\\"combined\\\": {\\\"loss\\\": [0.2423906810581684, 0.18283199984580278, 0.1432144525460899, 0.10053108679130673, 0.08877436281181872]}}, \\\"test\\\": {\\\"hazardous\\\": {\\\"loss\\\": [0.24164335429668427, 0.1789311170578003, 0.1416245996952057, 0.10085224360227585, 0.08724308758974075], \\\"roc_auc\\\": [0.8597664833068848, 0.9339866042137146, 0.9626750946044922, 0.9782354235649109, 0.9823563694953918], \\\"accuracy\\\": [0.8983621001243591, 0.9078475832939148, 0.9363591074943542, 0.9568741917610168, 0.9670214653015137]}, \\\"combined\\\": {\\\"loss\\\": [0.24880694830790162, 0.1840855125337839, 0.14615480555221438, 0.10501336632296443, 0.09107050858438015]}}}\",\n    \"eval_stats\": \"{}\",\n    \"trial_id\": \"bdcfb194\",\n    \"trial_dir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_bdcfb194/\",\n    \"time_this_iter_s\": 18.358004808425903,\n    \"should_checkpoint\": true,\n    \"done\": false,\n    \"timesteps_total\": null,\n    \"episodes_total\": null,\n    \"training_iteration\": 5,\n    \"experiment_id\": \"56cbcbb321a94bfebd773b50aac83eca\",\n    \"date\": \"2022-06-29_18-29-52\",\n    \"timestamp\": 1656541792,\n    \"time_total_s\": 100.2118079662323,\n    \"pid\": 72872,\n    \"hostname\": \"C02FR8FUMD6R.grubhub.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"trainer.learning_rate\": 0.005,\n      \"trainer.batch_size\": 512,\n      \"trainer.decay_rate\": 0.9,\n      \"trainer.decay_steps\": 8000,\n      \"combiner.size\": 16,\n      \"combiner.output_size\": 16,\n      \"combiner.num_steps\": 3,\n      \"combiner.relaxation_factor\": 1.2,\n      \"combiner.sparsity\": 0.01,\n      \"combiner.bn_virtual_bs\": 256,\n      \"combiner.bn_momentum\": 0.4\n    },\n    \"time_since_restore\": 100.2118079662323,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 5,\n    \"warmup_time\": 0.0047969818115234375,\n    \"experiment_tag\": \"6_combiner_bn_momentum=0.4000,combiner_bn_virtual_bs=256,combiner_num_steps=3,combiner_output_size=16,combiner_relaxation_factor=1.2000,combiner_size=16,combiner_sparsity=0.0100,trainer_batch_size=512,trainer_decay_rate=0.9000,trainer_decay_steps=8000,trainer_learning_rate=0.0050\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1656541792.382522,\n  \"metric_analysis\": {\n    \"metric_score\": {\n      \"max\": 0.9842120409011841,\n      \"min\": 0.8621048927307129,\n      \"avg\": 0.944492781162262,\n      \"last\": 0.9842120409011841,\n      \"last-5-avg\": 0.944492781162262,\n      \"last-10-avg\": 0.944492781162262\n    },\n    \"time_this_iter_s\": {\n      \"max\": 23.769936323165894,\n      \"min\": 16.777764797210693,\n      \"avg\": 20.04236159324646,\n      \"last\": 18.358004808425903,\n      \"last-5-avg\": 20.04236159324646,\n      \"last-10-avg\": 20.04236159324646\n    },\n    \"should_checkpoint\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": 1.0,\n      \"last\": true,\n      \"last-5-avg\": 1.0,\n      \"last-10-avg\": 1.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 5,\n      \"min\": 1,\n      \"avg\": 3.0,\n      \"last\": 5,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    },\n    \"time_total_s\": {\n      \"max\": 100.2118079662323,\n      \"min\": 16.777764797210693,\n      \"avg\": 60.17509422302246,\n      \"last\": 100.2118079662323,\n      \"last-5-avg\": 60.17509422302246,\n      \"last-10-avg\": 60.17509422302246\n    },\n    \"time_since_restore\": {\n      \"max\": 100.2118079662323,\n      \"min\": 16.777764797210693,\n      \"avg\": 60.17509422302246,\n      \"last\": 100.2118079662323,\n      \"last-5-avg\": 60.17509422302246,\n      \"last-10-avg\": 60.17509422302246\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 5,\n      \"min\": 1,\n      \"avg\": 3.0,\n      \"last\": 5,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    },\n    \"warmup_time\": {\n      \"max\": 0.0047969818115234375,\n      \"min\": 0.0047969818115234375,\n      \"avg\": 0.0047969818115234375,\n      \"last\": 0.0047969818115234375,\n      \"last-5-avg\": 0.0047969818115234375,\n      \"last-10-avg\": 0.0047969818115234375\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"metric_score\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473feb965d00000000473fedd953a0000000473feeccb8c0000000473fef635900000000473fef7eaa40000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473feb965d00000000473fedd953a0000000473feeccb8c0000000473fef635900000000473fef7eaa40000000652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474030c71b98000000474037c51a8c000000474034efcb1c0000004740345e91980000004740325ba634000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474030c71b98000000474037c51a8c000000474034efcb1c0000004740345e91980000004740325ba634000000652e\"\n      }\n    },\n    \"should_checkpoint\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288888888888652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288888888888652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288989898989652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b034b044b05652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b05652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474030c71b98000000474044461b1200000047404ebe00a000000047405476a4b60000004740590d8e43000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474030c71b98000000474044461b1200000047404ebe00a000000047405476a4b60000004740590d8e43000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474030c71b98000000474044461b1200000047404ebe00a000000047405476a4b60000004740590d8e43000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474030c71b98000000474044461b1200000047404ebe00a000000047405476a4b60000004740590d8e43000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b024b034b044b05652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b05652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473f73a60000000000473f73a60000000000473f73a60000000000473f73a60000000000473f73a60000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473f73a60000000000473f73a60000000000473f73a60000000000473f73a60000000000473f73a60000000000652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"start_time\": 1656541684.031927,\n  \"logdir\": \"/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/trial_bdcfb194\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": null,\n  \"pickled_error_file\": null,\n  \"trial_name_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd2024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"trial_dirname_creator\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595f2020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b014b004b014b024b53430c64017c006a009b009d025300944e8c06747269616c5f9486948c08747269616c5f69649485948c05747269616c9485948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e7079948c083c6c616d6264613e944dd3024300942929749452947d94288c0b5f5f7061636b6167655f5f948c0f6c75647769672e68797065726f7074948c085f5f6e616d655f5f948c196c75647769672e68797065726f70742e657865637574696f6e948c085f5f66696c655f5f948c6b2f55736572732f73616e61646b61742f5079636861726d50726f6a656374732f6c75647769672d6175746f6d6c2f76656e762f6c69622f707974686f6e332e372f736974652d7061636b616765732f6c75647769672f68797065726f70742f657865637574696f6e2e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681d7d947d9428681868118c0c5f5f7175616c6e616d655f5f948c2952617954756e654578656375746f722e657865637574652e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468198c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n  },\n  \"custom_trial_name\": \"trial_bdcfb194\",\n  \"custom_dirname\": \"trial_bdcfb194\",\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_function_tpl\": null,\n  \"checkpoint_freq\": 0,\n  \"checkpoint_at_end\": false,\n  \"keep_checkpoints_num\": 1,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"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\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_insufficient_resources_manager": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "8005958b000000000000008c277261792e74756e652e696e73756666696369656e745f7265736f75726365735f6d616e61676572948c1c496e73756666696369656e745265736f75726365734d616e616765729493942981947d94288c185f6e6f5f72756e6e696e675f747269616c735f73696e6365944affffffff8c0f5f6c6173745f747269616c5f6e756d944affffffff75622e"
    },
    "_max_pending_trials": 1,
    "_metric": "metric_score",
    "_total_time": 918.681058883667,
    "_iteration": 75,
    "_has_errored": false,
    "_fail_fast": false,
    "_server_port": null,
    "_cached_trial_decisions": {
      "bdcb6684": "STOP"
    },
    "_queued_trial_decisions": {},
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "800595d6000000000000008c107261792e74756e652e73746f70706572948c0f436f6d62696e656453746f707065729493942981947d948c095f73746f7070657273948c196c75647769672e68797065726f70742e657865637574696f6e948c0f43616c6c6261636b53746f707065729493942981947d948c0963616c6c6261636b73945d94736268008c0e54696d656f757453746f707065729493942981947d94288c105f74696d656f75745f7365636f6e6473944b788c075f6275646765749447bfc4c3b8000000008c0b5f6c6173745f636865636b944e7562869473622e"
    },
    "_resumed": true,
    "checkpoint_file": "/Users/sanadkat/PycharmProjects/ludwig-automl/hyperopt/experiment_state-2022-06-29_18-38-19.json",
    "_session_str": "2022-06-29_18-38-19",
    "_start_time": 1656542299.094539,
    "_last_checkpoint_time": -Infinity,
    "_checkpoint_period": "auto",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1656542299.094539,
    "timestamp": 0.0
  }
}